{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b79e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d507f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image:171\n",
      "Train Label:171\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cpu\")\n",
    "trainimagePath='yolo_model/dataset/images/train'\n",
    "trainlabelPath='yolo_model/dataset/labels/train/FASTER-RCNN'\n",
    "valimagePath='yolo_model/dataset/images/val'\n",
    "vallabelPath='yolo_model/dataset/labels/val/FASTER-RCNN'\n",
    "\n",
    "label_txt = []\n",
    "delete = []\n",
    "\n",
    "print(\"Train Image:\" + str(len(os.listdir(trainimagePath))))\n",
    "print(\"Train Label:\" +str(len(os.listdir(trainlabelPath))))\n",
    "for filename in os.listdir(trainlabelPath):\n",
    "    word = filename[:-4]\n",
    "    label_txt.append(word)\n",
    "for file in os.listdir(trainimagePath):\n",
    "    if file[:-4] not in label_txt:\n",
    "        delete.append(file)\n",
    "print(delete)\n",
    "print(len(delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eeefe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Image:168\n",
      "Val Label:168\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "label_txt = []\n",
    "delete = []\n",
    "print(\"Val Image:\" +str(len(os.listdir(valimagePath))))\n",
    "print(\"Val Label:\" +str(len(os.listdir(vallabelPath))))\n",
    "for filename in os.listdir(vallabelPath):\n",
    "    word = filename[:-4]\n",
    "    label_txt.append(word)\n",
    "for file in os.listdir(valimagePath):\n",
    "    if file[:-4] not in label_txt:\n",
    "        delete.append(file)\n",
    "print(delete)\n",
    "print(len(delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c3b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets.voc as VOC\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# xml library for parsing xml files\n",
    "from xml.etree import ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95787499",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'yolo_model/dataset/images/train/'\n",
    "trainlabelPath='yolo_model/dataset/labels/train/FASTER-RCNN'\n",
    "test_dir = 'yolo_model/dataset/images/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85f513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class MaizeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir,label_dir, width, height, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        #sort images for consistency\n",
    "        self.imgs = [image for image in sorted(os.listdir(train_dir)) if image[-3:] == 'jpg']\n",
    "        self.classes = ['_', 'Maize']\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.imgs[index]\n",
    "        image_path = os.path.join(self.img_dir, img_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img_res = cv2.resize(img_rgb, (self.width, self.height), cv2.INTER_AREA)\n",
    "        \n",
    "        #divide all pixels rgb vals by 255\n",
    "        img_res /= 255.0\n",
    "\n",
    "        #annotation file\n",
    "        annot_filename = img_name[:-4] + '.xml'\n",
    "        annot_file_path = os.path.join(self.label_dir, annot_filename)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        tree = et.parse(annot_file_path)\n",
    "\n",
    "        root = tree.getroot()\n",
    "\n",
    "        wt = img.shape[1]\n",
    "        ht = img.shape[0]\n",
    "\n",
    "        #box coordinates for xml files are extracted\n",
    "        for member in root.findall('object'):\n",
    "            labels.append(self.classes.index(member.find('name').text))\n",
    "            \n",
    "            #bounding box x coords\n",
    "            xmin = int(member.find('bndbox').find('xmin').text)\n",
    "            xmax = int(member.find('bndbox').find('xmax').text)\n",
    "            \n",
    "            #bounding box y coords\n",
    "            ymin = int(member.find('bndbox').find('ymin').text)\n",
    "            ymax = int(member.find('bndbox').find('ymax').text)\n",
    "\n",
    "            xmin_corr = (xmin/wt)*self.width\n",
    "            xmax_corr = (xmax/wt)*self.width\n",
    "            ymin_corr = (ymin/ht)*self.height\n",
    "            ymax_corr = (ymax/ht)*self.height\n",
    "\n",
    "            boxes.append([xmin_corr, ymin_corr, xmax_corr, ymax_corr])\n",
    "\n",
    "        #convert boxes into tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        #areas of the boxes\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        #image_id\n",
    "        image_id = torch.tensor([index])\n",
    "        target[\"image_id\"] = image_id\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=img_res, bboxes=target['boxes'], labels=labels)\n",
    "            img_res = sample['image']\n",
    "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
    "\n",
    "        return img_res, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0804f8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here's dataset length:  171\n"
     ]
    }
   ],
   "source": [
    "train_data = MaizeDataset(train_dir,trainlabelPath, 224, 224)\n",
    "print(\"here's dataset length: \", len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7978bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the image:  (224, 224, 3)\n",
      "target:  {'boxes': tensor([[ 32.3596, 132.3860,  38.5000, 139.5088]]), 'labels': tensor([1]), 'area': tensor([43.7365]), 'iscrowd': tensor([0]), 'image_id': tensor([24])}\n"
     ]
    }
   ],
   "source": [
    "my_img, my_target = train_data[24]\n",
    "print(\"shape of the image: \", my_img.shape)\n",
    "print(\"target: \", my_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a79aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
