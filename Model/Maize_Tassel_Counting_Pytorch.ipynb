{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.htmlNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torch==1.10.0+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp38-cp38-win_amd64.whl (2442.4 MB)\n",
      "Collecting torchvision==0.11.1+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.1%2Bcu113-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting torchaudio===0.10.0+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.10.0%2Bcu113-cp38-cp38-win_amd64.whl (336 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch==1.10.0+cu113) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from torchvision==0.11.1+cu113) (1.19.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in d:\\anaconda3\\lib\\site-packages (from torchvision==0.11.1+cu113) (8.0.1)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0+cu92\n",
      "    Uninstalling torch-1.4.0+cu92:\n",
      "      Successfully uninstalled torch-1.4.0+cu92\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1\n",
      "    Uninstalling torchvision-0.11.1:\n",
      "      Successfully uninstalled torchvision-0.11.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.10.0\n",
      "    Uninstalling torchaudio-0.10.0:\n",
      "      Successfully uninstalled torchaudio-0.10.0\n",
      "Successfully installed torch-1.10.0+cu113 torchaudio-0.10.0+cu113 torchvision-0.11.1+cu113\n"
     ]
    }
   ],
   "source": [
    "#pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9752, 0.2226, 0.2277],\n",
      "        [0.2493, 0.1693, 0.7396],\n",
      "        [0.7140, 0.3910, 0.2681],\n",
      "        [0.8534, 0.7624, 0.1596],\n",
      "        [0.5297, 0.4789, 0.5907]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gen_trainval_list.py\n",
    "\n",
    "This portion of the code seems to be only writing the image name and its corresponding mat files into a txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'maize_counting_dataset'\n",
    "image_folder = 'images'\n",
    "label_folder = 'labels'\n",
    "train = 'train'\n",
    "val = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(root, train)\n",
    "with open('train.txt', 'w') as f:\n",
    "    for image_path in glob.glob(os.path.join(train_path, image_folder, '*.JPG')):\n",
    "        im_path = image_path.replace(root, '')\n",
    "        gt_path = im_path.replace(image_folder, label_folder).replace('.JPG', '.xml')\n",
    "        f.write(im_path+'\\t'+gt_path+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = os.path.join(root, val)\n",
    "with open('val.txt', 'w') as f:\n",
    "    for image_path in glob.glob(os.path.join(val_path, image_folder, '*.JPG')):\n",
    "        im_path = image_path.replace(root, '')\n",
    "        gt_path = im_path.replace(image_folder, label_folder).replace('.JPG', '.xml')\n",
    "        f.write(im_path+'\\t'+gt_path+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hldataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd \n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage import util\n",
    "from skimage.measure import label\n",
    "from skimage.measure import regionprops\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(x):\n",
    "    img_arr = np.array(Image.open(x))\n",
    "    if len(img_arr.shape) == 2:  # grayscale\n",
    "        img_arr = np.tile(img_arr, [3, 1, 1]).transpose(1, 2, 0)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "\n",
    "        image, target, gtcount = sample['image'], sample['target'], sample['gtcount']\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        if isinstance(self.output_size, tuple):\n",
    "            new_h = min(self.output_size[0], h)\n",
    "            new_w = min(self.output_size[1], w)\n",
    "            assert (new_h, new_w) == self.output_size\n",
    "        else:\n",
    "            crop_size = min(self.output_size, h, w)\n",
    "            assert crop_size == self.output_size\n",
    "            new_h = new_w = crop_size\n",
    "        if gtcount > 0:\n",
    "            mask = target > 0\n",
    "            ch, cw = int(np.ceil(new_h / 2)), int(np.ceil(new_w / 2))\n",
    "            mask_center = np.zeros((h, w), dtype=np.uint8)\n",
    "            mask_center[ch:h-ch+1, cw:w-cw+1] = 1\n",
    "            mask = (mask & mask_center)\n",
    "            idh, idw = np.where(mask == 1)\n",
    "            if len(idh) != 0:\n",
    "                ids = random.choice(range(len(idh)))\n",
    "                hc, wc = idh[ids], idw[ids]\n",
    "                top, left = hc-ch, wc-cw\n",
    "            else:\n",
    "                top = np.random.randint(0, h-new_h+1)\n",
    "                left = np.random.randint(0, w-new_w+1)\n",
    "        else:\n",
    "            top = np.random.randint(0, h-new_h+1)\n",
    "            left = np.random.randint(0, w-new_w+1)\n",
    "\n",
    "        image = image[top:top+new_h, left:left+new_w, :]\n",
    "        target = target[top:top+new_h, left:left+new_w]\n",
    "\n",
    "        return {'image': image, 'target': target, 'gtcount': gtcount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFlip(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, target, gtcount = sample['image'], sample['target'], sample['gtcount']\n",
    "        do_mirror = np.random.randint(2)\n",
    "        if do_mirror:\n",
    "            image = cv2.flip(image, 1)\n",
    "            target = cv2.flip(target, 1)\n",
    "        return {'image': image, 'target': target, 'gtcount': gtcount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "\n",
    "    def __init__(self, scale, mean, std):\n",
    "        self.scale = scale\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, target, gtcount = sample['image'], sample['target'], sample['gtcount']\n",
    "        image, target = image.astype('float32'), target.astype('float32')\n",
    "\n",
    "        # pixel normalization\n",
    "        image = (self.scale * image - self.mean) / self.std\n",
    "\n",
    "        image, target = image.astype('float32'), target.astype('float32')\n",
    "\n",
    "        return {'image': image, 'target': target, 'gtcount': gtcount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroPadding(object):\n",
    "    def __init__(self, psize=32):\n",
    "        self.psize = psize\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        psize =  self.psize\n",
    "\n",
    "        image, target, gtcount = sample['image'], sample['target'], sample['gtcount']\n",
    "        h,w = image.size()[-2:]\n",
    "        ph,pw = (psize-h%psize),(psize-w%psize)\n",
    "        # print(ph,pw)\n",
    "\n",
    "        (pl, pr) = (pw//2, pw-pw//2) if pw != psize else (0, 0)\n",
    "        (pt, pb) = (ph//2, ph-ph//2) if ph != psize else (0, 0)\n",
    "        if (ph!=psize) or (pw!=psize):\n",
    "            tmp_pad = [pl, pr, pt, pb]\n",
    "            # print(tmp_pad)\n",
    "            image = F.pad(image,tmp_pad)\n",
    "            target = F.pad(target,tmp_pad)\n",
    "\n",
    "        return {'image': image, 'target': target, 'gtcount': gtcount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # swap color axis\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image, target, gtcount = sample['image'], sample['target'], sample['gtcount']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        target = np.expand_dims(target, axis=2)\n",
    "        target = target.transpose((2, 0, 1))\n",
    "        image, target = torch.from_numpy(image), torch.from_numpy(target)\n",
    "        return {'image': image, 'target': target, 'gtcount': gtcount}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaizeTasselDataset(Dataset):\n",
    "    def __init__(self, data_dir, data_list, ratio, train=True, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_list = [name.split('\\t') for name in open(data_list).read().splitlines()]\n",
    "        self.ratio = ratio\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.image_list = []\n",
    "        \n",
    "        # store images and generate ground truths\n",
    "        self.images = {}\n",
    "        self.targets = {}\n",
    "        self.gtcounts = {}\n",
    "        self.dotimages = {}\n",
    "\n",
    "    def bbs2points(self, bbs):    \n",
    "        points = []\n",
    "        for bb in bbs:\n",
    "            x1, y1, w, h = [float(b) for b in bb]\n",
    "            x2, y2 = x1+w-1, y1+h-1\n",
    "            x, y = np.round((x1+x2)/2).astype(np.int32), np.round((y1+y2)/2).astype(np.int32)\n",
    "            points.append([x, y])\n",
    "        return points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.data_list[idx]\n",
    "        self.image_list.append(file_name[0])\n",
    "        if file_name[0] not in self.images:\n",
    "            image = read_image(self.data_dir+file_name[0])\n",
    "            annotation = sio.loadmat(self.data_dir+file_name[1])\n",
    "            h, w = image.shape[:2]\n",
    "            nh = int(np.ceil(h * self.ratio))\n",
    "            nw = int(np.ceil(w * self.ratio))\n",
    "            image = cv2.resize(image, (nw, nh), interpolation = cv2.INTER_CUBIC)\n",
    "            target = np.zeros((nh, nw), dtype=np.float32)\n",
    "            dotimage = image.copy()\n",
    "            if annotation['annotation'][0][0][1] is not None:\n",
    "                bbs = annotation['annotation'][0][0][1]\n",
    "                gtcount = bbs.shape[0]\n",
    "                pts = self.bbs2points(bbs)\n",
    "                for pt in pts:\n",
    "                    pt[0], pt[1] = int(pt[0] * self.ratio), int(pt[1] * self.ratio)\n",
    "                    target[pt[1], pt[0]] = 1\n",
    "                    cv2.circle(dotimage, (pt[0], pt[1]), int(24 * self.ratio) , (255, 0, 0), -1)\n",
    "            else:\n",
    "                gtcount = 0\n",
    "            target = gaussian_filter(target, 80 * self.ratio)\n",
    "\n",
    "            # plt.imshow(target, cmap=cm.jet)\n",
    "            # plt.show()\n",
    "            # print(target.sum())\n",
    "\n",
    "            self.images.update({file_name[0]:image})\n",
    "            self.targets.update({file_name[0]:target})\n",
    "            self.gtcounts.update({file_name[0]:gtcount})\n",
    "            self.dotimages.update({file_name[0]:dotimage})\n",
    "\n",
    "        \n",
    "        sample = {\n",
    "            'image': self.images[file_name[0]], \n",
    "            'target': self.targets[file_name[0]], \n",
    "            'gtcount': self.gtcounts[file_name[0]]\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaizeTasselDataset(\n",
    "        data_dir='maize_counting_dataset', \n",
    "        data_list='maize_counting_dataset/train.txt',\n",
    "        ratio=0.167, \n",
    "        train=True, \n",
    "        transform=transforms.Compose([\n",
    "            ToTensor()]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "torch.Size([1, 3, 278770])\n",
      "0\n",
      "torch.Size([1, 3, 278770])\n",
      "1\n",
      "torch.Size([1, 3, 278770])\n",
      "2\n",
      "torch.Size([1, 3, 278770])\n",
      "3\n",
      "torch.Size([1, 3, 278770])\n",
      "4\n",
      "torch.Size([1, 3, 222530])\n",
      "5\n",
      "torch.Size([1, 3, 278770])\n",
      "6\n",
      "torch.Size([1, 3, 222530])\n",
      "7\n",
      "torch.Size([1, 3, 278770])\n",
      "8\n",
      "torch.Size([1, 3, 278770])\n",
      "9\n",
      "torch.Size([1, 3, 278770])\n",
      "10\n",
      "torch.Size([1, 3, 278770])\n",
      "11\n",
      "torch.Size([1, 3, 278770])\n",
      "12\n",
      "torch.Size([1, 3, 278770])\n",
      "13\n",
      "torch.Size([1, 3, 278770])\n",
      "14\n",
      "torch.Size([1, 3, 278770])\n",
      "15\n",
      "torch.Size([1, 3, 278770])\n",
      "16\n",
      "torch.Size([1, 3, 278770])\n",
      "17\n",
      "torch.Size([1, 3, 278770])\n",
      "18\n",
      "torch.Size([1, 3, 278770])\n",
      "19\n",
      "torch.Size([1, 3, 278770])\n",
      "20\n",
      "torch.Size([1, 3, 278770])\n",
      "21\n",
      "torch.Size([1, 3, 278770])\n",
      "22\n",
      "torch.Size([1, 3, 278770])\n",
      "23\n",
      "torch.Size([1, 3, 278770])\n",
      "24\n",
      "torch.Size([1, 3, 278770])\n",
      "25\n",
      "torch.Size([1, 3, 278770])\n",
      "26\n",
      "torch.Size([1, 3, 278770])\n",
      "27\n",
      "torch.Size([1, 3, 278770])\n",
      "28\n",
      "torch.Size([1, 3, 278770])\n",
      "29\n",
      "torch.Size([1, 3, 278770])\n",
      "30\n",
      "torch.Size([1, 3, 278770])\n",
      "31\n",
      "torch.Size([1, 3, 278770])\n",
      "32\n",
      "torch.Size([1, 3, 278770])\n",
      "33\n",
      "torch.Size([1, 3, 278770])\n",
      "34\n",
      "torch.Size([1, 3, 278770])\n",
      "35\n",
      "torch.Size([1, 3, 278770])\n",
      "36\n",
      "torch.Size([1, 3, 278770])\n",
      "37\n",
      "torch.Size([1, 3, 278770])\n",
      "38\n",
      "torch.Size([1, 3, 278770])\n",
      "39\n",
      "torch.Size([1, 3, 278770])\n",
      "40\n",
      "torch.Size([1, 3, 278770])\n",
      "41\n",
      "torch.Size([1, 3, 278770])\n",
      "42\n",
      "torch.Size([1, 3, 278770])\n",
      "43\n",
      "torch.Size([1, 3, 278770])\n",
      "44\n",
      "torch.Size([1, 3, 278770])\n",
      "45\n",
      "torch.Size([1, 3, 278770])\n",
      "46\n",
      "torch.Size([1, 3, 222530])\n",
      "47\n",
      "torch.Size([1, 3, 278770])\n",
      "48\n",
      "torch.Size([1, 3, 278770])\n",
      "49\n",
      "torch.Size([1, 3, 278770])\n",
      "50\n",
      "torch.Size([1, 3, 278770])\n",
      "51\n",
      "torch.Size([1, 3, 278770])\n",
      "52\n",
      "torch.Size([1, 3, 278770])\n",
      "53\n",
      "torch.Size([1, 3, 278770])\n",
      "54\n",
      "torch.Size([1, 3, 278770])\n",
      "55\n",
      "torch.Size([1, 3, 278770])\n",
      "56\n",
      "torch.Size([1, 3, 278770])\n",
      "57\n",
      "torch.Size([1, 3, 278770])\n",
      "58\n",
      "torch.Size([1, 3, 278770])\n",
      "59\n",
      "torch.Size([1, 3, 278770])\n",
      "60\n",
      "torch.Size([1, 3, 222530])\n",
      "61\n",
      "torch.Size([1, 3, 278770])\n",
      "62\n",
      "torch.Size([1, 3, 278770])\n",
      "63\n",
      "torch.Size([1, 3, 278770])\n",
      "64\n",
      "torch.Size([1, 3, 278770])\n",
      "65\n",
      "torch.Size([1, 3, 278770])\n",
      "66\n",
      "torch.Size([1, 3, 222530])\n",
      "67\n",
      "torch.Size([1, 3, 278770])\n",
      "68\n",
      "torch.Size([1, 3, 278770])\n",
      "69\n",
      "torch.Size([1, 3, 278770])\n",
      "70\n",
      "torch.Size([1, 3, 278770])\n",
      "71\n",
      "torch.Size([1, 3, 278770])\n",
      "72\n",
      "torch.Size([1, 3, 278770])\n",
      "73\n",
      "torch.Size([1, 3, 278770])\n",
      "74\n",
      "torch.Size([1, 3, 222530])\n",
      "75\n",
      "torch.Size([1, 3, 278770])\n",
      "76\n",
      "torch.Size([1, 3, 278770])\n",
      "77\n",
      "torch.Size([1, 3, 278770])\n",
      "78\n",
      "torch.Size([1, 3, 278770])\n",
      "79\n",
      "torch.Size([1, 3, 278770])\n",
      "80\n",
      "torch.Size([1, 3, 278770])\n",
      "81\n",
      "torch.Size([1, 3, 278770])\n",
      "82\n",
      "torch.Size([1, 3, 278770])\n",
      "83\n",
      "torch.Size([1, 3, 278770])\n",
      "84\n",
      "torch.Size([1, 3, 278770])\n",
      "85\n",
      "torch.Size([1, 3, 278770])\n",
      "86\n",
      "torch.Size([1, 3, 278770])\n",
      "87\n",
      "torch.Size([1, 3, 278770])\n",
      "88\n",
      "torch.Size([1, 3, 278770])\n",
      "89\n",
      "torch.Size([1, 3, 278770])\n",
      "90\n",
      "torch.Size([1, 3, 278770])\n",
      "91\n",
      "torch.Size([1, 3, 222530])\n",
      "92\n",
      "torch.Size([1, 3, 278770])\n",
      "93\n",
      "torch.Size([1, 3, 278770])\n",
      "94\n",
      "torch.Size([1, 3, 278770])\n",
      "95\n",
      "torch.Size([1, 3, 222530])\n",
      "96\n",
      "torch.Size([1, 3, 278770])\n",
      "97\n",
      "torch.Size([1, 3, 278770])\n",
      "98\n",
      "torch.Size([1, 3, 278770])\n",
      "99\n",
      "torch.Size([1, 3, 278770])\n",
      "100\n",
      "torch.Size([1, 3, 278770])\n",
      "101\n",
      "torch.Size([1, 3, 278770])\n",
      "102\n",
      "torch.Size([1, 3, 278770])\n",
      "103\n",
      "torch.Size([1, 3, 278770])\n",
      "104\n",
      "torch.Size([1, 3, 278770])\n",
      "105\n",
      "torch.Size([1, 3, 278770])\n",
      "106\n",
      "torch.Size([1, 3, 278770])\n",
      "107\n",
      "torch.Size([1, 3, 278770])\n",
      "108\n",
      "torch.Size([1, 3, 278770])\n",
      "109\n",
      "torch.Size([1, 3, 278770])\n",
      "110\n",
      "torch.Size([1, 3, 278770])\n",
      "111\n",
      "torch.Size([1, 3, 278770])\n",
      "112\n",
      "torch.Size([1, 3, 222530])\n",
      "113\n",
      "torch.Size([1, 3, 278770])\n",
      "114\n",
      "torch.Size([1, 3, 278770])\n",
      "115\n",
      "torch.Size([1, 3, 278770])\n",
      "116\n",
      "torch.Size([1, 3, 278770])\n",
      "117\n",
      "torch.Size([1, 3, 278770])\n",
      "118\n",
      "torch.Size([1, 3, 278770])\n",
      "119\n",
      "torch.Size([1, 3, 278770])\n",
      "120\n",
      "torch.Size([1, 3, 278770])\n",
      "121\n",
      "torch.Size([1, 3, 278770])\n",
      "122\n",
      "torch.Size([1, 3, 278770])\n",
      "123\n",
      "torch.Size([1, 3, 278770])\n",
      "124\n",
      "torch.Size([1, 3, 278770])\n",
      "125\n",
      "torch.Size([1, 3, 278770])\n",
      "126\n",
      "torch.Size([1, 3, 278770])\n",
      "127\n",
      "torch.Size([1, 3, 278770])\n",
      "128\n",
      "torch.Size([1, 3, 278770])\n",
      "129\n",
      "torch.Size([1, 3, 278770])\n",
      "130\n",
      "torch.Size([1, 3, 278770])\n",
      "131\n",
      "torch.Size([1, 3, 278770])\n",
      "132\n",
      "torch.Size([1, 3, 278770])\n",
      "133\n",
      "torch.Size([1, 3, 278770])\n",
      "134\n",
      "torch.Size([1, 3, 278770])\n",
      "135\n",
      "torch.Size([1, 3, 278770])\n",
      "136\n",
      "torch.Size([1, 3, 278770])\n",
      "137\n",
      "torch.Size([1, 3, 278770])\n",
      "138\n",
      "torch.Size([1, 3, 278770])\n",
      "139\n",
      "torch.Size([1, 3, 278770])\n",
      "140\n",
      "torch.Size([1, 3, 278770])\n",
      "141\n",
      "torch.Size([1, 3, 278770])\n",
      "142\n",
      "torch.Size([1, 3, 278770])\n",
      "143\n",
      "torch.Size([1, 3, 278770])\n",
      "144\n",
      "torch.Size([1, 3, 278770])\n",
      "145\n",
      "torch.Size([1, 3, 278770])\n",
      "146\n",
      "torch.Size([1, 3, 278770])\n",
      "147\n",
      "torch.Size([1, 3, 278770])\n",
      "148\n",
      "torch.Size([1, 3, 278770])\n",
      "149\n",
      "torch.Size([1, 3, 278770])\n",
      "150\n",
      "torch.Size([1, 3, 222530])\n",
      "151\n",
      "torch.Size([1, 3, 278770])\n",
      "152\n",
      "torch.Size([1, 3, 278770])\n",
      "153\n",
      "torch.Size([1, 3, 278770])\n",
      "154\n",
      "torch.Size([1, 3, 278770])\n",
      "155\n",
      "torch.Size([1, 3, 278770])\n",
      "156\n",
      "torch.Size([1, 3, 278770])\n",
      "157\n",
      "torch.Size([1, 3, 278770])\n",
      "158\n",
      "torch.Size([1, 3, 278770])\n",
      "159\n",
      "torch.Size([1, 3, 278770])\n",
      "160\n",
      "torch.Size([1, 3, 222530])\n",
      "161\n",
      "torch.Size([1, 3, 278770])\n",
      "162\n",
      "torch.Size([1, 3, 278770])\n",
      "163\n",
      "torch.Size([1, 3, 278770])\n",
      "164\n",
      "torch.Size([1, 3, 278770])\n",
      "165\n",
      "torch.Size([1, 3, 278770])\n",
      "166\n",
      "torch.Size([1, 3, 278770])\n",
      "167\n",
      "torch.Size([1, 3, 278770])\n",
      "168\n",
      "torch.Size([1, 3, 278770])\n",
      "169\n",
      "torch.Size([1, 3, 278770])\n",
      "170\n",
      "torch.Size([1, 3, 278770])\n",
      "171\n",
      "torch.Size([1, 3, 278770])\n",
      "172\n",
      "torch.Size([1, 3, 278770])\n",
      "173\n",
      "torch.Size([1, 3, 278770])\n",
      "174\n",
      "torch.Size([1, 3, 222530])\n",
      "175\n",
      "torch.Size([1, 3, 278770])\n",
      "176\n",
      "torch.Size([1, 3, 278770])\n",
      "177\n",
      "torch.Size([1, 3, 278770])\n",
      "178\n",
      "torch.Size([1, 3, 278770])\n",
      "179\n",
      "torch.Size([1, 3, 278770])\n",
      "180\n",
      "torch.Size([1, 3, 278770])\n",
      "181\n",
      "torch.Size([1, 3, 278770])\n",
      "182\n",
      "torch.Size([1, 3, 278770])\n",
      "183\n",
      "torch.Size([1, 3, 278770])\n",
      "184\n",
      "torch.Size([1, 3, 278770])\n",
      "185\n",
      "tensor([0.3862, 0.4908, 0.2898])\n",
      "tensor([0.1718, 0.1712, 0.1519])\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader))\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "        images, targets = data['image'], data['target']\n",
    "        bs = images.size(0)\n",
    "        images = images.view(bs, images.size(1), -1).float()\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        print(images.size())\n",
    "        print(i) \n",
    "mean /= len(dataloader)\n",
    "std /= len(dataloader)\n",
    "print(mean/255.)\n",
    "print(std/255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2 as cv\n",
    "from scipy.ndimage import gaussian_filter, morphology\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(pd, gt):\n",
    "    pd, gt = np.array(pd), np.array(gt)\n",
    "    diff = pd - gt\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    return mae\n",
    "\n",
    "\n",
    "def compute_mse(pd, gt):\n",
    "    pd, gt = np.array(pd), np.array(gt)\n",
    "    diff = pd - gt\n",
    "    mse = np.sqrt(np.mean((diff ** 2)))\n",
    "    return mse\n",
    "\n",
    "def compute_relerr(pd, gt):\n",
    "    pd, gt = np.array(pd), np.array(gt)\n",
    "    diff = pd - gt\n",
    "    diff = diff[gt > 0]\n",
    "    gt = gt[gt > 0]\n",
    "    if (diff is not None) and (gt is not None):\n",
    "        rmae = np.mean(np.abs(diff) / gt) * 100\n",
    "        rmse = np.sqrt(np.mean(diff**2 / gt**2)) * 100\n",
    "    else:\n",
    "        rmae = 0\n",
    "        rmse = 0\n",
    "    return rmae, rmse\n",
    "\n",
    "\n",
    "def rsquared(pd, gt):\n",
    "    \"\"\" Return R^2 where x and y are array-like.\"\"\"\n",
    "    pd, gt = np.array(pd), np.array(gt)\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(pd, gt)\n",
    "    return r_value**2\n",
    "\n",
    "\n",
    "def dense_sample2d(x, sx, stride):\n",
    "    (h,w) = x.shape[:2]\n",
    "    #idx_img = np.array([i for i in range(h*w)]).reshape(h,w)\n",
    "    idx_img = np.zeros((h,w),dtype=float)\n",
    "    \n",
    "    th = [i for i in range(0, h-sx+1, stride)]\n",
    "    tw = [j for j in range(0, w-sx+1, stride)]\n",
    "    norm_vec = np.zeros(len(th)*len(tw))\n",
    "\n",
    "    for i in th:\n",
    "        for j in tw:\n",
    "            idx_img[i:i+sx,j:j+sx] = idx_img[i:i+sx,j:j+sx]+1\n",
    "\n",
    "    # plot redundancy map\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    cmap = plt.cm.get_cmap('hot')\n",
    "    idx_img = idx_img / (idx_img.max())\n",
    "    idx_img = cmap(idx_img) * 255.\n",
    "    plt.figure()\n",
    "    plt.imshow(idx_img.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join('redundancy_map.pdf'), bbox_inches='tight', dpi = 300)\n",
    "    plt.close()\n",
    "   \n",
    "    idx_img = 1/idx_img\n",
    "    idx_img = idx_img/sx/sx\n",
    "    #line order\n",
    "    idx = 0\n",
    "    for i in th:\n",
    "        for j in tw:\n",
    "            norm_vec[idx] =idx_img[i:i+sx,j:j+sx].sum()\n",
    "            idx+=1\n",
    "    \n",
    "    return norm_vec\n",
    "\n",
    "\n",
    "def recover_countmap(pred, image, patch_sz, stride):\n",
    "    pred = pred.reshape(-1)\n",
    "    imH, imW = image.shape[2:4]\n",
    "    cntMap = np.zeros((imH, imW), dtype=float)\n",
    "    norMap = np.zeros((imH, imW), dtype=float)\n",
    "    \n",
    "    H = np.arange(0, imH - patch_sz + 1, stride)\n",
    "    W = np.arange(0, imW - patch_sz + 1, stride)\n",
    "    cnt = 0\n",
    "    for h in H:\n",
    "        for w in W:\n",
    "            pixel_cnt = pred[cnt] / patch_sz / patch_sz\n",
    "            cntMap[h:h+patch_sz, w:w+patch_sz] += pixel_cnt\n",
    "            norMap[h:h+patch_sz, w:w+patch_sz] += np.ones((patch_sz,patch_sz))\n",
    "            cnt += 1\n",
    "    return cntMap / (norMap + 1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hlnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, arc='tasselnetv2'):\n",
    "        super(Encoder, self).__init__()\n",
    "        if arc == 'tasselnetv2':\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d((2, 2), stride=2),\n",
    "                nn.Conv2d(16, 32, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d((2, 2), stride=2),\n",
    "                nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d((2, 2), stride=2),\n",
    "                nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        elif arc == 'tasselnetv2plus':\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d((2, 2), stride=2),\n",
    "                nn.Conv2d(16, 32, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d((2, 2), stride=2),\n",
    "                nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d((2, 2), stride=2),\n",
    "                nn.Conv2d(64, 128, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter(nn.Module):\n",
    "    def __init__(self, arc='tasselnetv2', input_size=64, output_stride=8):\n",
    "        super(Counter, self).__init__()\n",
    "        k = int(input_size / 8)\n",
    "        avg_pool_stride = int(output_stride / 8)\n",
    "\n",
    "        if arc == 'tasselnetv2':\n",
    "            self.counter = nn.Sequential(\n",
    "                nn.Conv2d(128, 128, (k, k), bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 128, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 1, 1)\n",
    "            )\n",
    "        elif arc == 'tasselnetv2plus':\n",
    "            self.counter = nn.Sequential(\n",
    "                nn.AvgPool2d((k, k), stride=avg_pool_stride),\n",
    "                nn.Conv2d(128, 128, 1, bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(128, 1, 1)\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.counter(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    @staticmethod\n",
    "    def cpu_normalizer(x, imh, imw, insz, os):\n",
    "        # CPU normalization\n",
    "        bs = x.size()[0]\n",
    "        normx = np.zeros((imh, imw))\n",
    "        norm_vec = dense_sample2d(normx, insz, os).astype(np.float32)\n",
    "        x = x.cpu().detach().numpy().reshape(bs, -1) * norm_vec\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def gpu_normalizer(x, imh, imw, insz, os):\n",
    "        _, _, h, w = x.size()            \n",
    "        accm = torch.cuda.FloatTensor(1, insz*insz, h*w).fill_(1)           \n",
    "        accm = F.fold(accm, (imh, imw), kernel_size=insz, stride=os)\n",
    "        accm = 1 / accm\n",
    "        accm /= insz**2\n",
    "        accm = F.unfold(accm, kernel_size=insz, stride=os).sum(1).view(1, 1, h, w)\n",
    "        x *= accm\n",
    "        return x.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountingModels(nn.Module):\n",
    "    def __init__(self, arc='tasselnetv2', input_size=64, output_stride=8):\n",
    "        super(CountingModels, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_stride = output_stride\n",
    "\n",
    "        self.encoder = Encoder(arc)\n",
    "        self.counter = Counter(arc, input_size, output_stride)\n",
    "        if arc == 'tasselnetv2':\n",
    "            self.normalizer = Normalizer.cpu_normalizer\n",
    "        elif arc == 'tasselnetv2plus':\n",
    "            self.normalizer = Normalizer.gpu_normalizer\n",
    "        \n",
    "        self.weight_init()\n",
    "\n",
    "    def forward(self, x, is_normalize=True):\n",
    "        imh, imw = x.size()[2:]\n",
    "        x = self.encoder(x)\n",
    "        x = self.counter(x)\n",
    "        if is_normalize:\n",
    "            x = self.normalizer(x, imh, imw, self.input_size, self.output_stride)\n",
    "        return x\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "                # nn.init.kaiming_uniform_(\n",
    "                #         m.weight, \n",
    "                #         mode='fan_in', \n",
    "                #         nonlinearity='relu'\n",
    "                #         )\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-9a25d3e4bf17>:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idx_img = 1/idx_img\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 29824)\n",
      "0.4462365785926013\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "insz, os = 64, 8\n",
    "imH, imW = 1080, 1920\n",
    "#net = CountingModels(arc='tasselnetv2', input_size=insz, output_stride=os).cuda()\n",
    "net = CountingModels(arc='tasselnetv2', input_size=insz, output_stride=os)\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    #x = torch.randn(1, 3, imH, imW).cuda()\n",
    "    x = torch.randn(1, 3, imH, imW)\n",
    "    y = net(x)\n",
    "    print(y.shape)    \n",
    "\n",
    "with torch.no_grad():\n",
    "    frame_rate = np.zeros((100, 1))\n",
    "    for i in range(100):\n",
    "        #x = torch.randn(1, 3, imH, imW).cuda()\n",
    "        x = torch.randn(1, 3, imH, imW)\n",
    "        #torch.cuda.synchronize()\n",
    "        start = time()\n",
    "\n",
    "        y = net(x)\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        end = time()\n",
    "\n",
    "        running_frame_rate = 1 * float(1 / (end - start))\n",
    "        frame_rate[i] = running_frame_rate\n",
    "    print(np.mean(frame_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hltrainval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from time import time\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "# from skimage.measure import compare_psnr updated to peak_signal_noise_ratio\n",
    "# from skimage.measure import compare_ssim updated to structural_similarity\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent dataloader deadlock, uncomment if deadlock occurs\n",
    "# cv.setNumThreads(0)\n",
    "#cudnn.enabled = True\n",
    "\n",
    "# constant\n",
    "IMG_SCALE = 1. / 255\n",
    "IMG_MEAN = [.3405, .4747, .2418]\n",
    "IMG_STD = [1, 1, 1]\n",
    "SCALES = [0.7, 1, 1.3]\n",
    "SHORTER_SIDE = 224\n",
    "\n",
    "# system-related parameters\n",
    "DATA_DIR = 'maize_counting_dataset'\n",
    "DATASET = 'mtc'\n",
    "EXP = 'tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500'\n",
    "DATA_LIST = 'maize_counting_dataset/train.txt'\n",
    "DATA_VAL_LIST = 'maize_counting_dataset/test.txt'\n",
    "\n",
    "RESTORE_FROM = 'model_best.pth.tar'\n",
    "SNAPSHOT_DIR = './snapshots'\n",
    "RESULT_DIR = './results'\n",
    "\n",
    "# model-related parameters\n",
    "INPUT_SIZE = 64\n",
    "OUTPUT_STRIDE = 8\n",
    "MODEL = 'tasselnetv2'\n",
    "RESIZE_RATIO = 0.125\n",
    "\n",
    "# training-related parameters\n",
    "OPTIMIZER = 'sgd'  # choice in ['sgd', 'adam']\n",
    "BATCH_SIZE = 9\n",
    "CROP_SIZE = (256, 256)\n",
    "LEARNING_RATE = 1e-2\n",
    "MILESTONES = [200, 400]\n",
    "MOMENTUM = 0.95\n",
    "MULT = 1\n",
    "NUM_EPOCHS = 500\n",
    "NUM_CPU_WORKERS = 0\n",
    "PRINT_EVERY = 1\n",
    "RANDOM_SEED = 6\n",
    "WEIGHT_DECAY = 5e-4\n",
    "VAL_EVERY = 1\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# add a new entry here if creating a new data loader\n",
    "dataset_list = {\n",
    "    'mtc': MaizeTasselDataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    \"\"\"Parse all the arguments provided from the CLI.\n",
    "\n",
    "    Returns:\n",
    "      A list of parsed arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Object Counting Framework\")\n",
    "    # constant\n",
    "    parser.add_argument(\"--image-scale\", type=float, default=IMG_SCALE, help=\"Scale factor used in normalization.\")\n",
    "    parser.add_argument(\"--image-mean\", nargs='+', type=float, default=IMG_MEAN, help=\"Mean used in normalization.\")\n",
    "    parser.add_argument(\"--image-std\", nargs='+', type=float, default=IMG_STD, help=\"Std used in normalization.\")\n",
    "    parser.add_argument(\"--scales\", type=int, default=SCALES, help=\"Scales of crop.\")\n",
    "    parser.add_argument(\"--shorter-side\", type=int, default=SHORTER_SIDE, help=\"Shorter side of the image.\")\n",
    "    # system-related parameters\n",
    "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIR, help=\"Path to the directory containing the dataset.\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default=DATASET, help=\"Dataset type.\")\n",
    "    parser.add_argument(\"--exp\", type=str, default=EXP, help=\"Experiment path.\")\n",
    "    parser.add_argument(\"--data-list\", type=str, default=DATA_LIST,\n",
    "                        help=\"Path to the file listing the images in the dataset.\")\n",
    "    parser.add_argument(\"--data-val-list\", type=str, default=DATA_VAL_LIST,\n",
    "                        help=\"Path to the file listing the images in the val dataset.\")\n",
    "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM, help=\"Name of restored model.\")\n",
    "    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR, help=\"Where to save snapshots of the model.\")\n",
    "    parser.add_argument(\"--result-dir\", type=str, default=RESULT_DIR, help=\"Where to save inferred results.\")\n",
    "    parser.add_argument(\"--save-output\", action=\"store_true\", help=\"Whether to save the output.\")\n",
    "    # model-related parameters\n",
    "    parser.add_argument(\"--input-size\", type=int, default=INPUT_SIZE, help=\"the minimum input size of the model.\")\n",
    "    parser.add_argument(\"--output-stride\", type=int, default=OUTPUT_STRIDE, help=\"Output stride of the model.\")\n",
    "    parser.add_argument(\"--resize-ratio\", type=float, default=RESIZE_RATIO, help=\"Resizing ratio.\")\n",
    "    parser.add_argument(\"--model\", type=str, default=MODEL, help=\"model to be chosen.\")\n",
    "    parser.add_argument(\"--use-pretrained\", action=\"store_true\", help=\"Whether to use pretrained model.\")\n",
    "    parser.add_argument(\"--freeze-bn\", action=\"store_true\", help=\"Whether to freeze encoder bnorm layers.\")\n",
    "    parser.add_argument(\"--sync-bn\", action=\"store_true\", help=\"Whether to apply synchronized batch normalization.\")\n",
    "    # training-related parameters\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=OPTIMIZER, choices=['sgd', 'adam'], help=\"Choose optimizer.\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=BATCH_SIZE,\n",
    "                        help=\"Number of images sent to the network in one step.\")\n",
    "    parser.add_argument(\"--milestones\", nargs='+', type=int, default=MILESTONES, help=\"Multistep policy.\")\n",
    "    parser.add_argument(\"--crop-size\", nargs='+', type=int, default=CROP_SIZE, help=\"Size of crop.\")\n",
    "    parser.add_argument(\"--evaluate-only\", action=\"store_true\", help=\"Whether to perform evaluation.\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=LEARNING_RATE, help=\"Base learning rate for training.\")\n",
    "    parser.add_argument(\"--momentum\", type=float, default=MOMENTUM, help=\"Momentum component of the optimizer.\")\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=WEIGHT_DECAY,\n",
    "                        help=\"Regularisation parameter for L2-loss.\")\n",
    "    parser.add_argument(\"--mult\", type=float, default=MULT, help=\"LR multiplier for pretrained layers.\")\n",
    "    parser.add_argument(\"--num-epochs\", type=int, default=NUM_EPOCHS, help=\"Number of training epochs.\")\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=NUM_CPU_WORKERS, help=\"Number of CPU cores used.\")\n",
    "    parser.add_argument(\"--print-every\", type=int, default=PRINT_EVERY, help=\"Print information every often.\")\n",
    "    parser.add_argument(\"--random-seed\", type=int, default=RANDOM_SEED,\n",
    "                        help=\"Random seed to have reproducible results.\")\n",
    "    parser.add_argument(\"--val-every\", type=int, default=VAL_EVERY, help=\"How often performing validation.\")\n",
    "    return parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, snapshot_dir, filename='model_ckpt.pth.tar'):\n",
    "    torch.save(state, '{}/{}'.format(snapshot_dir, filename))\n",
    "\n",
    "\n",
    "def plot_learning_curves(net, dir_to_save):\n",
    "    # plot learning curves\n",
    "    fig = plt.figure(figsize=(16, 9))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(net.train_loss['epoch_loss'], label='train loss', color='tab:blue')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.plot(net.val_loss['epoch_loss'], label='val mae', color='tab:orange')\n",
    "    ax2.legend(loc='upper right')\n",
    "    # ax2.set_ylim((0,50))\n",
    "    fig.savefig(os.path.join(dir_to_save, 'learning_curves.png'), bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFTER EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, criterion, optimizer, epoch, args):\n",
    "    # switch to 'train' mode\n",
    "    net.train()\n",
    "\n",
    "    # uncomment the following line if the training images don't have the same size\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if BATCH_SIZE == 1:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    avg_frame_rate = 0.0\n",
    "    in_sz = INPUT_SIZE\n",
    "    os = OUTPUT_STRIDE\n",
    "    #target_filter = torch.cuda.FloatTensor(1, 1, in_sz, in_sz).fill_(1)\n",
    "    target_filter = torch.FloatTensor(1, 1, in_sz, in_sz).fill_(1)\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        #torch.cuda.synchronize()\n",
    "        start = time()\n",
    "\n",
    "        inputs, targets = sample['image'], sample['target']\n",
    "        #inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = net(inputs, is_normalize=False)\n",
    "        # generate targets\n",
    "        targets = F.conv2d(targets, target_filter, stride=os)\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # collect and print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #torch.cuda.synchronize()\n",
    "        end = time()\n",
    "\n",
    "        running_frame_rate = BATCH_SIZE * float(1 / (end - start))\n",
    "        avg_frame_rate = (avg_frame_rate * i + running_frame_rate) / (i + 1)\n",
    "        if i % PRINT_EVERY == PRINT_EVERY - 1:\n",
    "            print('epoch: %d, train: %d/%d, '\n",
    "                  'loss: %.5f, frame: %.2fHz/%.2fHz' % (\n",
    "                      epoch,\n",
    "                      i + 1,\n",
    "                      len(train_loader),\n",
    "                      running_loss / (i + 1),\n",
    "                      running_frame_rate,\n",
    "                      avg_frame_rate\n",
    "                  ))\n",
    "    net.train_loss['epoch_loss'].append(running_loss / (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, valset, val_loader, criterion, epoch, args):\n",
    "    # switch to 'eval' mode\n",
    "    net.eval()\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    image_list = valset.image_list\n",
    "\n",
    "    #if args.save_output:\n",
    "     #   epoch_result_dir = os.path.join(args.result_dir, str(epoch))\n",
    "      #  if not os.path.exists(epoch_result_dir):\n",
    "       #     os.makedirs(epoch_result_dir)\n",
    "        #cmap = plt.cm.get_cmap('jet')\n",
    "    epoch_result_dir = os.path.join(RESULT_DIR, str(epoch))\n",
    "    if not os.path.exists(epoch_result_dir):\n",
    "        os.makedirs(epoch_result_dir)\n",
    "    cmap = plt.cm.get_cmap('jet')\n",
    "    \n",
    "    pd_counts = []\n",
    "    gt_counts = []\n",
    "    with torch.no_grad():\n",
    "        avg_frame_rate = 0.0\n",
    "        for i, sample in enumerate(val_loader):\n",
    "            #torch.cuda.synchronize()\n",
    "            start = time()\n",
    "\n",
    "            image, gtcount = sample['image'], sample['gtcount']\n",
    "            # inference\n",
    "            #output = net(image.cuda(), is_normalize=not args.save_output)\n",
    "            output = net(image, is_normalize = False)\n",
    "            #if args.save_output:\n",
    "            #    output_save = output\n",
    "                # normalization\n",
    "            #    output = Normalizer.gpu_normalizer(output, image.size()[2], image.size()[3], args.input_size,\n",
    "            #                                       args.output_stride)\n",
    "            output_save = output\n",
    "            output = Normalizer.cpu_normalizer(output, image.size()[2], image.size()[3], INPUT_SIZE,\n",
    "                                                   OUTPUT_STRIDE)\n",
    "            \n",
    "            # postprocessing\n",
    "            output = np.clip(output, 0, None)\n",
    "\n",
    "            pdcount = output.sum()\n",
    "            gtcount = float(gtcount.numpy())\n",
    "\n",
    "            #if args.save_output:\n",
    "            x = True\n",
    "            if x:\n",
    "                _, image_name = os.path.split(image_list[i])\n",
    "                output_save = np.clip(output_save.squeeze().cpu().numpy(), 0, None)\n",
    "                output_save = recover_countmap(output_save, image, INPUT_SIZE, OUTPUT_STRIDE)\n",
    "                output_save = output_save / (output_save.max() + 1e-12)\n",
    "                output_save = cmap(output_save) * 255.\n",
    "                # image composition\n",
    "                image = valset.images[image_list[i]]\n",
    "                nh, nw = output_save.shape[:2]\n",
    "                image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "                output_save = 0.5 * image + 0.5 * output_save[:, :, 0:3]\n",
    "\n",
    "                dotimage = valset.dotimages[image_list[i]]\n",
    "\n",
    "                fig = plt.figure()\n",
    "                ax1 = fig.add_subplot(1, 2, 1)\n",
    "                ax1.imshow(dotimage.astype(np.uint8))\n",
    "                ax1.get_xaxis().set_visible(False)\n",
    "                ax1.get_yaxis().set_visible(False)\n",
    "                ax2 = fig.add_subplot(1, 2, 2)\n",
    "                ax2.imshow(output_save.astype(np.uint8))\n",
    "                ax2.get_xaxis().set_visible(False)\n",
    "                ax2.get_yaxis().set_visible(False)\n",
    "                fig.suptitle('manual count=%4.2f, inferred count=%4.2f' % (gtcount, pdcount), fontsize=10)\n",
    "                if DATASET == 'mtc':\n",
    "                    plt.tight_layout(rect=[0, 0, 1, 1.4])  # maize tassels counting\n",
    "                elif DATASET == 'wec':\n",
    "                    plt.tight_layout(rect=[0, 0, 1, 1.45])  # wheat ears counting\n",
    "                elif DATASET == 'shc':\n",
    "                    plt.tight_layout(rect=[0, 0, 0.95, 1])  # sorghum heads counting -- dataset1\n",
    "                    # plt.tight_layout(rect=[0, 0, 1.2, 1]) # sorghum heads counting -- dataset2\n",
    "                plt.savefig(os.path.join(epoch_result_dir, image_name.replace('.jpg', '.png')), bbox_inches='tight',\n",
    "                            dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            # compute mae and mse\n",
    "            pd_counts.append(pdcount)\n",
    "            gt_counts.append(gtcount)\n",
    "            mae = compute_mae(pd_counts, gt_counts)\n",
    "            mse = compute_mse(pd_counts, gt_counts)\n",
    "            rmae, rmse = compute_relerr(pd_counts, gt_counts)\n",
    "\n",
    "            #torch.cuda.synchronize()\n",
    "            end = time()\n",
    "\n",
    "            running_frame_rate = 1 * float(1 / (end - start))\n",
    "            avg_frame_rate = (avg_frame_rate * i + running_frame_rate) / (i + 1)\n",
    "            if i % PRINT_EVERY == PRINT_EVERY - 1:\n",
    "                print(\n",
    "                    'epoch: {0}, test: {1}/{2}, pre: {3:.2f}, gt:{4:.2f}, me:{5:.2f}, mae: {6:.2f}, mse: {7:.2f}, rmae: {8:.2f}%, rmse: {9:.2f}%, frame: {10:.2f}Hz/{11:.2f}Hz'\n",
    "                        .format(epoch, i + 1, len(val_loader), pdcount, gtcount, pdcount - gtcount, mae, mse, rmae,\n",
    "                                rmse, running_frame_rate, avg_frame_rate)\n",
    "                )\n",
    "            start = time()\n",
    "    r2 = rsquared(pd_counts, gt_counts)\n",
    "    np.save(SNAPSHOT_DIR + '/pd.npy', pd_counts)\n",
    "    np.save(SNAPSHOT_DIR + '/gt.npy', gt_counts)\n",
    "    print('epoch: {0}, mae: {1:.2f}, mse: {2:.2f}, rmae: {3:.2f}%, rmse: {4:.2f}%, r2: {5:.4f}'.format(epoch, mae, mse,\n",
    "                                                                                                       rmae, rmse, r2))\n",
    "    # write to files        \n",
    "    with open(os.path.join(SNAPSHOT_DIR, EXP + '.txt'), 'a') as f:\n",
    "        print(\n",
    "            'epoch: {0}, mae: {1:.2f}, mse: {2:.2f}, rmae: {3:.2f}%, rmse: {4:.2f}%, r2: {5:.4f}'.format(epoch, mae,\n",
    "                                                                                                         mse, rmae,\n",
    "                                                                                                         rmse, r2),\n",
    "            file=f\n",
    "        )\n",
    "    with open(os.path.join(SNAPSHOT_DIR, 'counts.txt'), 'a') as f:\n",
    "        for pd, gt in zip(pd_counts, gt_counts):\n",
    "            print(\n",
    "                '{0} {1}'.format(pd, gt),\n",
    "                file=f\n",
    "            )\n",
    "    # save stats\n",
    "    net.val_loss['epoch_loss'].append(mae)\n",
    "    net.measure['mae'].append(mae)\n",
    "    net.measure['mse'].append(mse)\n",
    "    net.measure['rmae'].append(rmae)\n",
    "    net.measure['rmse'].append(rmse)\n",
    "    net.measure['r2'].append(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, criterion, optimizer, epoch, args):\n",
    "    # switch to 'train' mode\n",
    "    net.train()\n",
    "\n",
    "    # uncomment the following line if the training images don't have the same size\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if args.batch_size == 1:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    avg_frame_rate = 0.0\n",
    "    in_sz = args.input_size\n",
    "    os = args.output_stride\n",
    "    target_filter = torch.cuda.FloatTensor(1, 1, in_sz, in_sz).fill_(1)\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time()\n",
    "\n",
    "        inputs, targets = sample['image'], sample['target']\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = net(inputs, is_normalize=False)\n",
    "        # generate targets\n",
    "        targets = F.conv2d(targets, target_filter, stride=os)\n",
    "        # compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # collect and print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time()\n",
    "\n",
    "        running_frame_rate = args.batch_size * float(1 / (end - start))\n",
    "        avg_frame_rate = (avg_frame_rate * i + running_frame_rate) / (i + 1)\n",
    "        if i % args.print_every == args.print_every - 1:\n",
    "            print('epoch: %d, train: %d/%d, '\n",
    "                  'loss: %.5f, frame: %.2fHz/%.2fHz' % (\n",
    "                      epoch,\n",
    "                      i + 1,\n",
    "                      len(train_loader),\n",
    "                      running_loss / (i + 1),\n",
    "                      running_frame_rate,\n",
    "                      avg_frame_rate\n",
    "                  ))\n",
    "    net.train_loss['epoch_loss'].append(running_loss / (i + 1))\n",
    "\n",
    "\n",
    "def validate(net, valset, val_loader, criterion, epoch, args):\n",
    "    # switch to 'eval' mode\n",
    "    net.eval()\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    image_list = valset.image_list\n",
    "\n",
    "    if args.save_output:\n",
    "        epoch_result_dir = os.path.join(args.result_dir, str(epoch))\n",
    "        if not os.path.exists(epoch_result_dir):\n",
    "            os.makedirs(epoch_result_dir)\n",
    "        cmap = plt.cm.get_cmap('jet')\n",
    "\n",
    "    pd_counts = []\n",
    "    gt_counts = []\n",
    "    with torch.no_grad():\n",
    "        avg_frame_rate = 0.0\n",
    "        for i, sample in enumerate(val_loader):\n",
    "            torch.cuda.synchronize()\n",
    "            start = time()\n",
    "\n",
    "            image, gtcount = sample['image'], sample['gtcount']\n",
    "            # inference\n",
    "            output = net(image.cuda(), is_normalize=not args.save_output)\n",
    "            if args.save_output:\n",
    "                output_save = output\n",
    "                # normalization\n",
    "                output = Normalizer.gpu_normalizer(output, image.size()[2], image.size()[3], args.input_size,\n",
    "                                                   args.output_stride)\n",
    "            # postprocessing\n",
    "            output = np.clip(output, 0, None)\n",
    "\n",
    "            pdcount = output.sum()\n",
    "            gtcount = float(gtcount.numpy())\n",
    "\n",
    "            if args.save_output:\n",
    "                _, image_name = os.path.split(image_list[i])\n",
    "                output_save = np.clip(output_save.squeeze().cpu().numpy(), 0, None)\n",
    "                output_save = recover_countmap(output_save, image, args.input_size, args.output_stride)\n",
    "                output_save = output_save / (output_save.max() + 1e-12)\n",
    "                output_save = cmap(output_save) * 255.\n",
    "                # image composition\n",
    "                image = valset.images[image_list[i]]\n",
    "                nh, nw = output_save.shape[:2]\n",
    "                image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "                output_save = 0.5 * image + 0.5 * output_save[:, :, 0:3]\n",
    "\n",
    "                dotimage = valset.dotimages[image_list[i]]\n",
    "\n",
    "                fig = plt.figure()\n",
    "                ax1 = fig.add_subplot(1, 2, 1)\n",
    "                ax1.imshow(dotimage.astype(np.uint8))\n",
    "                ax1.get_xaxis().set_visible(False)\n",
    "                ax1.get_yaxis().set_visible(False)\n",
    "                ax2 = fig.add_subplot(1, 2, 2)\n",
    "                ax2.imshow(output_save.astype(np.uint8))\n",
    "                ax2.get_xaxis().set_visible(False)\n",
    "                ax2.get_yaxis().set_visible(False)\n",
    "                fig.suptitle('manual count=%4.2f, inferred count=%4.2f' % (gtcount, pdcount), fontsize=10)\n",
    "                if args.dataset == 'mtc':\n",
    "                    plt.tight_layout(rect=[0, 0, 1, 1.4])  # maize tassels counting\n",
    "                elif args.dataset == 'wec':\n",
    "                    plt.tight_layout(rect=[0, 0, 1, 1.45])  # wheat ears counting\n",
    "                elif args.dataset == 'shc':\n",
    "                    plt.tight_layout(rect=[0, 0, 0.95, 1])  # sorghum heads counting -- dataset1\n",
    "                    # plt.tight_layout(rect=[0, 0, 1.2, 1]) # sorghum heads counting -- dataset2\n",
    "                plt.savefig(os.path.join(epoch_result_dir, image_name.replace('.jpg', '.png')), bbox_inches='tight',\n",
    "                            dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            # compute mae and mse\n",
    "            pd_counts.append(pdcount)\n",
    "            gt_counts.append(gtcount)\n",
    "            mae = compute_mae(pd_counts, gt_counts)\n",
    "            mse = compute_mse(pd_counts, gt_counts)\n",
    "            rmae, rmse = compute_relerr(pd_counts, gt_counts)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            end = time()\n",
    "\n",
    "            running_frame_rate = 1 * float(1 / (end - start))\n",
    "            avg_frame_rate = (avg_frame_rate * i + running_frame_rate) / (i + 1)\n",
    "            if i % args.print_every == args.print_every - 1:\n",
    "                print(\n",
    "                    'epoch: {0}, test: {1}/{2}, pre: {3:.2f}, gt:{4:.2f}, me:{5:.2f}, mae: {6:.2f}, mse: {7:.2f}, rmae: {8:.2f}%, rmse: {9:.2f}%, frame: {10:.2f}Hz/{11:.2f}Hz'\n",
    "                        .format(epoch, i + 1, len(val_loader), pdcount, gtcount, pdcount - gtcount, mae, mse, rmae,\n",
    "                                rmse, running_frame_rate, avg_frame_rate)\n",
    "                )\n",
    "            start = time()\n",
    "    r2 = rsquared(pd_counts, gt_counts)\n",
    "    np.save(args.snapshot_dir + '/pd.npy', pd_counts)\n",
    "    np.save(args.snapshot_dir + '/gt.npy', gt_counts)\n",
    "    print('epoch: {0}, mae: {1:.2f}, mse: {2:.2f}, rmae: {3:.2f}%, rmse: {4:.2f}%, r2: {5:.4f}'.format(epoch, mae, mse,\n",
    "                                                                                                       rmae, rmse, r2))\n",
    "    # write to files        \n",
    "    with open(os.path.join(args.snapshot_dir, args.exp + '.txt'), 'a') as f:\n",
    "        print(\n",
    "            'epoch: {0}, mae: {1:.2f}, mse: {2:.2f}, rmae: {3:.2f}%, rmse: {4:.2f}%, r2: {5:.4f}'.format(epoch, mae,\n",
    "                                                                                                         mse, rmae,\n",
    "                                                                                                         rmse, r2),\n",
    "            file=f\n",
    "        )\n",
    "    with open(os.path.join(args.snapshot_dir, 'counts.txt'), 'a') as f:\n",
    "        for pd, gt in zip(pd_counts, gt_counts):\n",
    "            print(\n",
    "                '{0} {1}'.format(pd, gt),\n",
    "                file=f\n",
    "            )\n",
    "    # save stats\n",
    "    net.val_loss['epoch_loss'].append(mae)\n",
    "    net.measure['mae'].append(mae)\n",
    "    net.measure['mse'].append(mse)\n",
    "    net.measure['rmae'].append(rmae)\n",
    "    net.measure['rmse'].append(rmse)\n",
    "    net.measure['r2'].append(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFTER EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_MEAN = np.array(IMG_MEAN).reshape((1, 1, 3))\n",
    "IMG_STD = np.array(IMG_STD).reshape((1, 1, 3))\n",
    "\n",
    "CROP_SIZE = tuple(CROP_SIZE) if len(CROP_SIZE) > 1 else CROP_SIZE\n",
    "\n",
    "# seeding for reproducbility\n",
    "#if torch.cuda.is_available():\n",
    "    #torch.cuda.manual_seed(args.random_seed)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# instantiate dataset\n",
    "dataset = dataset_list[DATASET]\n",
    "\n",
    "SNAPSHOT_DIR = os.path.join(SNAPSHOT_DIR, DATASET.lower(), EXP)\n",
    "if not os.path.exists(SNAPSHOT_DIR):\n",
    "    os.makedirs(SNAPSHOT_DIR)\n",
    "\n",
    "RESULT_DIR = os.path.join(RESULT_DIR, DATASET.lower(), EXP)\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "RESTORE_FROM = os.path.join(SNAPSHOT_DIR, RESTORE_FROM)\n",
    "\n",
    "#arguments = vars(args)\n",
    "#for item in arguments:\n",
    "    #print(item, ':\\t', arguments[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument(\"--image-scale\", type=float, default=IMG_SCALE, help=\"Scale factor used in normalization.\")\n",
    "    parser.add_argument(\"--image-mean\", nargs='+', type=float, default=IMG_MEAN, help=\"Mean used in normalization.\")\n",
    "    parser.add_argument(\"--image-std\", nargs='+', type=float, default=IMG_STD, help=\"Std used in normalization.\")\n",
    "    parser.add_argument(\"--scales\", type=int, default=SCALES, help=\"Scales of crop.\")\n",
    "    parser.add_argument(\"--shorter-side\", type=int, default=SHORTER_SIDE, help=\"Shorter side of the image.\")\n",
    "    # system-related parameters\n",
    "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIR, help=\"Path to the directory containing the dataset.\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default=DATASET, help=\"Dataset type.\")\n",
    "    parser.add_argument(\"--exp\", type=str, default=EXP, help=\"Experiment path.\")\n",
    "    parser.add_argument(\"--data-list\", type=str, default=DATA_LIST,\n",
    "                        help=\"Path to the file listing the images in the dataset.\")\n",
    "    parser.add_argument(\"--data-val-list\", type=str, default=DATA_VAL_LIST,\n",
    "                        help=\"Path to the file listing the images in the val dataset.\")\n",
    "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM, help=\"Name of restored model.\")\n",
    "    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR, help=\"Where to save snapshots of the model.\")\n",
    "    parser.add_argument(\"--result-dir\", type=str, default=RESULT_DIR, help=\"Where to save inferred results.\")\n",
    "    parser.add_argument(\"--save-output\", action=\"store_true\", help=\"Whether to save the output.\")\n",
    "    # model-related parameters\n",
    "    parser.add_argument(\"--input-size\", type=int, default=INPUT_SIZE, help=\"the minimum input size of the model.\")\n",
    "    parser.add_argument(\"--output-stride\", type=int, default=OUTPUT_STRIDE, help=\"Output stride of the model.\")\n",
    "    parser.add_argument(\"--resize-ratio\", type=float, default=RESIZE_RATIO, help=\"Resizing ratio.\")\n",
    "    parser.add_argument(\"--model\", type=str, default=MODEL, help=\"model to be chosen.\")\n",
    "    parser.add_argument(\"--use-pretrained\", action=\"store_true\", help=\"Whether to use pretrained model.\")\n",
    "    parser.add_argument(\"--freeze-bn\", action=\"store_true\", help=\"Whether to freeze encoder bnorm layers.\")\n",
    "    parser.add_argument(\"--sync-bn\", action=\"store_true\", help=\"Whether to apply synchronized batch normalization.\")\n",
    "    # training-related parameters\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=OPTIMIZER, choices=['sgd', 'adam'], help=\"Choose optimizer.\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=BATCH_SIZE,\n",
    "                        help=\"Number of images sent to the network in one step.\")\n",
    "    parser.add_argument(\"--milestones\", nargs='+', type=int, default=MILESTONES, help=\"Multistep policy.\")\n",
    "    parser.add_argument(\"--crop-size\", nargs='+', type=int, default=CROP_SIZE, help=\"Size of crop.\")\n",
    "    parser.add_argument(\"--evaluate-only\", action=\"store_true\", help=\"Whether to perform evaluation.\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=LEARNING_RATE, help=\"Base learning rate for training.\")\n",
    "    parser.add_argument(\"--momentum\", type=float, default=MOMENTUM, help=\"Momentum component of the optimizer.\")\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=WEIGHT_DECAY,\n",
    "                        help=\"Regularisation parameter for L2-loss.\")\n",
    "    parser.add_argument(\"--mult\", type=float, default=MULT, help=\"LR multiplier for pretrained layers.\")\n",
    "    parser.add_argument(\"--num-epochs\", type=int, default=NUM_EPOCHS, help=\"Number of training epochs.\")\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=NUM_CPU_WORKERS, help=\"Number of CPU cores used.\")\n",
    "    parser.add_argument(\"--print-every\", type=int, default=PRINT_EVERY, help=\"Print information every often.\")\n",
    "    parser.add_argument(\"--random-seed\", type=int, default=RANDOM_SEED,\n",
    "                        help=\"Random seed to have reproducible results.\")\n",
    "    parser.add_argument(\"--val-every\", type=int, default=VAL_EVERY, help=\"How often performing validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_scale': 0.00392156862745098, 'image_mean': array([[[0.3405, 0.4747, 0.2418]]]), 'image_std': array([[[1, 1, 1]]]), 'scales': [0.7, 1, 1.3], 'shorter_side': 224, 'data_dir': 'maize_counting_dataset', 'dataset': 'mtc', 'exp': 'tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500', 'data_list': 'maize_counting_dataset/train.txt', 'data_val_list': 'maize_counting_dataset/test.txt', 'restore_from': './snapshots\\\\mtc\\\\tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500\\\\model_best.pth.tar', 'snapshot_dir': './snapshots\\\\mtc\\\\tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500', 'result_dir': './results\\\\mtc\\\\tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500', 'save_output': 'store_true', 'input_size': 64, 'output_stride': 8, 'resize_ratio': 0.125, 'model': 'tasselnetv2', 'optimizer': 'sgd', 'batch_size': 9, 'milestones': [200, 400], 'crop_size': (256, 256), 'evaluate_only': 'store_true', 'learning_rate': 0.01, 'momentum': 0.95, 'weight_decay': 0.0005, 'mult': 1, 'num_epochs': 500, 'num_workers': 0, 'print_every': 1, 'random_seed': 6, 'val_every': 1}\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"image_scale\":IMG_SCALE,\n",
    "    \"image_mean\":IMG_MEAN,\n",
    "    \"image_std\": IMG_STD,\n",
    "    \"scales\":SCALES,\n",
    "    \"shorter_side\":SHORTER_SIDE,\n",
    "    \"data_dir\":DATA_DIR,\n",
    "    \"dataset\":DATASET,\n",
    "    \"exp\":EXP,\n",
    "    \"data_list\":DATA_LIST,\n",
    "    \"data_val_list\":DATA_VAL_LIST,\n",
    "    \"restore_from\":RESTORE_FROM,\n",
    "    \"snapshot_dir\":SNAPSHOT_DIR,\n",
    "    \"result_dir\":RESULT_DIR,\n",
    "    \"save_output\":\"store_true\",\n",
    "    \"input_size\":INPUT_SIZE,\n",
    "    \"output_stride\":OUTPUT_STRIDE,\n",
    "    \"resize_ratio\":RESIZE_RATIO,\n",
    "    \"model\":MODEL,\n",
    "    \"optimizer\":OPTIMIZER,\n",
    "    \"batch_size\":BATCH_SIZE,\n",
    "    \"milestones\":MILESTONES,\n",
    "    \"crop_size\":CROP_SIZE,\n",
    "    \"evaluate_only\":\"store_true\",\n",
    "    \"learning_rate\":LEARNING_RATE,\n",
    "    \"momentum\":MOMENTUM,\n",
    "    \"weight_decay\":WEIGHT_DECAY,\n",
    "    \"mult\":MULT,\n",
    "    \"num_epochs\":NUM_EPOCHS,\n",
    "    \"num_workers\":NUM_CPU_WORKERS,\n",
    "    \"print_every\":PRINT_EVERY,\n",
    "    \"random_seed\":RANDOM_SEED,\n",
    "    \"val_every\":VAL_EVERY\n",
    "}\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'image_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ec8cf0b8ca60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# args.save_output = True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'image_mean'"
     ]
    }
   ],
   "source": [
    "#args = get_arguments()\n",
    "\n",
    "# args.evaluate_only = True\n",
    "# args.save_output = True\n",
    "\n",
    "args.image_mean = np.array(args.image_mean).reshape((1, 1, 3))\n",
    "args.image_std = np.array(args.image_std).reshape((1, 1, 3))\n",
    "\n",
    "args.crop_size = tuple(args.crop_size) if len(args.crop_size) > 1 else args.crop_size\n",
    "\n",
    "# seeding for reproducbility\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.random_seed)\n",
    "torch.manual_seed(args.random_seed)\n",
    "np.random.seed(args.random_seed)\n",
    "\n",
    "# instantiate dataset\n",
    "dataset = dataset_list[args.dataset]\n",
    "\n",
    "args.snapshot_dir = os.path.join(args.snapshot_dir, args.dataset.lower(), args.exp)\n",
    "if not os.path.exists(args.snapshot_dir):\n",
    "    os.makedirs(args.snapshot_dir)\n",
    "\n",
    "args.result_dir = os.path.join(args.result_dir, args.dataset.lower(), args.exp)\n",
    "if not os.path.exists(args.result_dir):\n",
    "    os.makedirs(args.result_dir)\n",
    "\n",
    "args.restore_from = os.path.join(args.snapshot_dir, args.restore_from)\n",
    "\n",
    "arguments = vars(args)\n",
    "for item in arguments:\n",
    "    print(item, ':\\t', arguments[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFTER EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate network\n",
    "net = CountingModels(\n",
    "      arc=MODEL,\n",
    "      input_size=INPUT_SIZE,\n",
    "      output_stride=OUTPUT_STRIDE\n",
    "    )\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "#net.cuda()\n",
    "\n",
    "# filter parameters\n",
    "learning_params = [p[1] for p in net.named_parameters()]\n",
    "pretrained_params = []\n",
    "\n",
    "# define loss function and optimizer\n",
    "#criterion = nn.L1Loss(reduction='mean').cuda()\n",
    "criterion = nn.L1Loss(reduction='mean')\n",
    "\n",
    "if OPTIMIZER == 'sgd':\n",
    "    optimizer = torch.optim.SGD(\n",
    "        [\n",
    "            {'params': learning_params},\n",
    "            {'params': pretrained_params, 'lr': LEARNING_RATE / MULT},\n",
    "        ],\n",
    "        lr=LEARNING_RATE,\n",
    "        momentum=MOMENTUM,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {'params': learning_params},\n",
    "            {'params': pretrained_params, 'lr': LEARNING_RATE / args.mult},\n",
    "        ],\n",
    "        lr=LEARNING_RATE\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> no checkpoint found at './snapshots\\mtc\\tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500\\model_best.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "# restore parameters\n",
    "start_epoch = 0\n",
    "net.train_loss = {\n",
    "    'running_loss': [],\n",
    "    'epoch_loss': []\n",
    "}\n",
    "net.val_loss = {\n",
    "    'running_loss': [],\n",
    "    'epoch_loss': []\n",
    "}\n",
    "net.measure = {\n",
    "    'mae': [],\n",
    "    'mse': [],\n",
    "    'rmae': [],\n",
    "    'rmse': [],\n",
    "    'r2': []\n",
    "}\n",
    "if RESTORE_FROM is not None:\n",
    "    if os.path.isfile(RESTORE_FROM):\n",
    "        checkpoint = torch.load(RESTORE_FROM)\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "        if 'epoch' in checkpoint:\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        if 'optimizer' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        if 'train_loss' in checkpoint:\n",
    "            net.train_loss = checkpoint['train_loss']\n",
    "        if 'val_loss' in checkpoint:\n",
    "            net.val_loss = checkpoint['val_loss']\n",
    "        if 'measure' in checkpoint:\n",
    "            net.measure['mae'] = checkpoint['measure']['mae'] if 'mae' in checkpoint['measure'] else []\n",
    "            net.measure['mse'] = checkpoint['measure']['mse'] if 'mse' in checkpoint['measure'] else []\n",
    "            net.measure['rmae'] = checkpoint['measure']['rmae'] if 'rmae' in checkpoint['measure'] else []\n",
    "            net.measure['rmse'] = checkpoint['measure']['rmse'] if 'rmse' in checkpoint['measure'] else []\n",
    "            net.measure['r2'] = checkpoint['measure']['r2'] if 'r2' in checkpoint['measure'] else []\n",
    "        print(\"==> load checkpoint '{}' (epoch {})\"\n",
    "              .format(RESTORE_FROM, start_epoch))\n",
    "    else:\n",
    "        with open(os.path.join(SNAPSHOT_DIR, EXP + '.txt'), 'a') as f:\n",
    "            for item in args:\n",
    "                print(item, ':\\t', args[item], file=f)\n",
    "        print(\"==> no checkpoint found at '{}'\".format(RESTORE_FROM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transform\n",
    "transform_train = [\n",
    "    RandomCrop(CROP_SIZE),\n",
    "    RandomFlip(),\n",
    "    Normalize(\n",
    "        IMG_SCALE,\n",
    "        IMG_MEAN,\n",
    "        IMG_STD\n",
    "    ),\n",
    "    ToTensor(),\n",
    "    ZeroPadding(OUTPUT_STRIDE)\n",
    "]\n",
    "transform_val = [\n",
    "    Normalize(\n",
    "        IMG_SCALE,\n",
    "        IMG_MEAN,\n",
    "        IMG_STD\n",
    "    ),\n",
    "    ToTensor(),\n",
    "    ZeroPadding(OUTPUT_STRIDE)\n",
    "]\n",
    "composed_transform_train = transforms.Compose(transform_train)\n",
    "composed_transform_val = transforms.Compose(transform_val)\n",
    "\n",
    "# define dataset loader\n",
    "trainset = dataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    data_list=DATA_LIST,\n",
    "    ratio=RESIZE_RATIO,\n",
    "    train=True,\n",
    "    transform=composed_transform_train\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_CPU_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "valset = dataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    data_list=DATA_LIST,\n",
    "    ratio=RESIZE_RATIO,\n",
    "    train=False,\n",
    "    transform=composed_transform_val\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_CPU_WORKERS,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-9a25d3e4bf17>:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idx_img = 1/idx_img\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test: 1/186, pre: inf, gt:97.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.49Hz/0.49Hz\n",
      "epoch: 0, test: 2/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.63Hz\n",
      "epoch: 0, test: 3/186, pre: inf, gt:23.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.67Hz\n",
      "epoch: 0, test: 4/186, pre: inf, gt:44.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.71Hz\n",
      "epoch: 0, test: 5/186, pre: inf, gt:32.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.73Hz\n",
      "epoch: 0, test: 6/186, pre: inf, gt:49.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.88Hz/0.75Hz\n",
      "epoch: 0, test: 7/186, pre: inf, gt:41.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.76Hz\n",
      "epoch: 0, test: 8/186, pre: inf, gt:60.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.96Hz/0.78Hz\n",
      "epoch: 0, test: 9/186, pre: inf, gt:32.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.85Hz/0.79Hz\n",
      "epoch: 0, test: 10/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 11/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.63Hz/0.78Hz\n",
      "epoch: 0, test: 12/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.78Hz\n",
      "epoch: 0, test: 13/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.78Hz\n",
      "epoch: 0, test: 14/186, pre: inf, gt:24.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.77Hz\n",
      "epoch: 0, test: 15/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.77Hz\n",
      "epoch: 0, test: 16/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.77Hz\n",
      "epoch: 0, test: 17/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.77Hz\n",
      "epoch: 0, test: 18/186, pre: inf, gt:50.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 19/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.77Hz\n",
      "epoch: 0, test: 20/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.78Hz\n",
      "epoch: 0, test: 21/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.77Hz\n",
      "epoch: 0, test: 22/186, pre: inf, gt:31.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 23/186, pre: inf, gt:102.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.78Hz\n",
      "epoch: 0, test: 24/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.77Hz\n",
      "epoch: 0, test: 25/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 26/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 27/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 28/186, pre: inf, gt:20.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 29/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 30/186, pre: inf, gt:83.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.78Hz\n",
      "epoch: 0, test: 31/186, pre: inf, gt:14.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.78Hz\n",
      "epoch: 0, test: 32/186, pre: inf, gt:19.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 33/186, pre: inf, gt:17.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 34/186, pre: inf, gt:9.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.78Hz\n",
      "epoch: 0, test: 35/186, pre: inf, gt:31.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 36/186, pre: inf, gt:5.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.78Hz\n",
      "epoch: 0, test: 37/186, pre: inf, gt:39.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.78Hz\n",
      "epoch: 0, test: 38/186, pre: inf, gt:94.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.78Hz\n",
      "epoch: 0, test: 39/186, pre: inf, gt:37.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.78Hz\n",
      "epoch: 0, test: 40/186, pre: inf, gt:68.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.78Hz\n",
      "epoch: 0, test: 41/186, pre: inf, gt:26.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.78Hz\n",
      "epoch: 0, test: 42/186, pre: inf, gt:37.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.78Hz\n",
      "epoch: 0, test: 43/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.78Hz\n",
      "epoch: 0, test: 44/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.78Hz\n",
      "epoch: 0, test: 45/186, pre: inf, gt:24.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 46/186, pre: inf, gt:83.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 47/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.78Hz\n",
      "epoch: 0, test: 48/186, pre: inf, gt:4.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.99Hz/0.78Hz\n",
      "epoch: 0, test: 49/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.85Hz/0.78Hz\n",
      "epoch: 0, test: 50/186, pre: inf, gt:37.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.78Hz\n",
      "epoch: 0, test: 51/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.78Hz\n",
      "epoch: 0, test: 52/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 53/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.78Hz\n",
      "epoch: 0, test: 54/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 55/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 56/186, pre: inf, gt:56.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 57/186, pre: inf, gt:53.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.78Hz\n",
      "epoch: 0, test: 58/186, pre: inf, gt:65.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.78Hz\n",
      "epoch: 0, test: 59/186, pre: inf, gt:21.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.78Hz\n",
      "epoch: 0, test: 60/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.78Hz\n",
      "epoch: 0, test: 61/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.78Hz\n",
      "epoch: 0, test: 62/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.96Hz/0.78Hz\n",
      "epoch: 0, test: 63/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.83Hz/0.78Hz\n",
      "epoch: 0, test: 64/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 65/186, pre: inf, gt:69.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 66/186, pre: inf, gt:65.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 67/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 68/186, pre: inf, gt:28.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 1.00Hz/0.79Hz\n",
      "epoch: 0, test: 69/186, pre: inf, gt:26.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.84Hz/0.79Hz\n",
      "epoch: 0, test: 70/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 71/186, pre: inf, gt:104.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.79Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test: 72/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.79Hz\n",
      "epoch: 0, test: 73/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 74/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.79Hz\n",
      "epoch: 0, test: 75/186, pre: inf, gt:35.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.79Hz\n",
      "epoch: 0, test: 76/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.95Hz/0.79Hz\n",
      "epoch: 0, test: 77/186, pre: inf, gt:14.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.84Hz/0.79Hz\n",
      "epoch: 0, test: 78/186, pre: inf, gt:13.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 79/186, pre: inf, gt:96.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 80/186, pre: inf, gt:9.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 81/186, pre: inf, gt:34.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.79Hz\n",
      "epoch: 0, test: 82/186, pre: inf, gt:68.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 83/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 84/186, pre: inf, gt:32.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 85/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 86/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.83Hz/0.79Hz\n",
      "epoch: 0, test: 87/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 88/186, pre: inf, gt:117.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 89/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 90/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 91/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.79Hz\n",
      "epoch: 0, test: 92/186, pre: inf, gt:2.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 93/186, pre: inf, gt:2.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.91Hz/0.79Hz\n",
      "epoch: 0, test: 94/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.79Hz\n",
      "epoch: 0, test: 95/186, pre: inf, gt:26.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.79Hz\n",
      "epoch: 0, test: 96/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 97/186, pre: inf, gt:59.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.97Hz/0.79Hz\n",
      "epoch: 0, test: 98/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.84Hz/0.79Hz\n",
      "epoch: 0, test: 99/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.84Hz/0.79Hz\n",
      "epoch: 0, test: 100/186, pre: inf, gt:71.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 101/186, pre: inf, gt:67.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 102/186, pre: inf, gt:17.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.83Hz/0.79Hz\n",
      "epoch: 0, test: 103/186, pre: inf, gt:13.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 104/186, pre: inf, gt:44.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 105/186, pre: inf, gt:54.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 106/186, pre: inf, gt:19.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 107/186, pre: inf, gt:17.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 108/186, pre: inf, gt:68.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 109/186, pre: inf, gt:19.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 110/186, pre: inf, gt:9.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 111/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.79Hz\n",
      "epoch: 0, test: 112/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 113/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 114/186, pre: inf, gt:2.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.94Hz/0.79Hz\n",
      "epoch: 0, test: 115/186, pre: inf, gt:56.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 116/186, pre: inf, gt:15.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 117/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 118/186, pre: inf, gt:47.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 119/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 120/186, pre: inf, gt:41.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 121/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.79Hz\n",
      "epoch: 0, test: 122/186, pre: inf, gt:61.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 123/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.79Hz\n",
      "epoch: 0, test: 124/186, pre: inf, gt:47.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 125/186, pre: inf, gt:47.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 126/186, pre: inf, gt:21.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.79Hz\n",
      "epoch: 0, test: 127/186, pre: inf, gt:15.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 128/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 129/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 130/186, pre: inf, gt:3.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.84Hz/0.79Hz\n",
      "epoch: 0, test: 131/186, pre: inf, gt:4.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.79Hz\n",
      "epoch: 0, test: 132/186, pre: inf, gt:70.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 133/186, pre: inf, gt:38.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 134/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 135/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 136/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 137/186, pre: inf, gt:85.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 138/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 139/186, pre: inf, gt:44.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 140/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 141/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test: 142/186, pre: inf, gt:96.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 143/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 144/186, pre: inf, gt:100.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 145/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 146/186, pre: inf, gt:48.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 147/186, pre: inf, gt:5.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 148/186, pre: inf, gt:65.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 149/186, pre: inf, gt:53.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.79Hz\n",
      "epoch: 0, test: 150/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 151/186, pre: inf, gt:57.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.79Hz\n",
      "epoch: 0, test: 152/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.93Hz/0.79Hz\n",
      "epoch: 0, test: 153/186, pre: inf, gt:69.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.79Hz\n",
      "epoch: 0, test: 154/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 155/186, pre: inf, gt:28.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 156/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 157/186, pre: inf, gt:5.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 158/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 159/186, pre: inf, gt:120.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.79Hz\n",
      "epoch: 0, test: 160/186, pre: inf, gt:70.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 161/186, pre: inf, gt:61.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.79Hz\n",
      "epoch: 0, test: 162/186, pre: inf, gt:24.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.92Hz/0.79Hz\n",
      "epoch: 0, test: 163/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.83Hz/0.79Hz\n",
      "epoch: 0, test: 164/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.79Hz\n",
      "epoch: 0, test: 165/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.79Hz\n",
      "epoch: 0, test: 166/186, pre: inf, gt:38.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.81Hz/0.79Hz\n",
      "epoch: 0, test: 167/186, pre: inf, gt:16.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 168/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 169/186, pre: inf, gt:16.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.79Hz\n",
      "epoch: 0, test: 170/186, pre: inf, gt:22.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 171/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.79Hz\n",
      "epoch: 0, test: 172/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 173/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.80Hz/0.79Hz\n",
      "epoch: 0, test: 174/186, pre: inf, gt:14.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 175/186, pre: inf, gt:54.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 176/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.92Hz/0.79Hz\n",
      "epoch: 0, test: 177/186, pre: inf, gt:41.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.85Hz/0.79Hz\n",
      "epoch: 0, test: 178/186, pre: inf, gt:46.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 179/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.79Hz\n",
      "epoch: 0, test: 180/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.79Hz\n",
      "epoch: 0, test: 181/186, pre: inf, gt:4.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n",
      "epoch: 0, test: 182/186, pre: inf, gt:12.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.79Hz\n",
      "epoch: 0, test: 183/186, pre: inf, gt:50.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 184/186, pre: inf, gt:33.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.79Hz\n",
      "epoch: 0, test: 185/186, pre: inf, gt:90.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.79Hz\n",
      "epoch: 0, test: 186/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.78Hz/0.79Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2474: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SNAPSHOT_DIRr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-96355ef38468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-78a9a9511393>\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(net, valset, val_loader, criterion, epoch, args)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrsquared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSNAPSHOT_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/pd.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSNAPSHOT_DIRr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/gt.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     print('epoch: {0}, mae: {1:.2f}, mse: {2:.2f}, rmae: {3:.2f}%, rmse: {4:.2f}%, r2: {5:.4f}'.format(epoch, mae, mse,\n\u001b[0;32m    105\u001b[0m                                                                                                        rmae, rmse, r2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SNAPSHOT_DIRr' is not defined"
     ]
    }
   ],
   "source": [
    "validate(net, valset, val_loader, criterion, start_epoch, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alchemy start...\n",
      "epoch: 1, train: 1/20, loss: 0.44639, frame: 16.20Hz/16.20Hz\n",
      "epoch: 1, train: 2/20, loss: 0.56881, frame: 15.53Hz/15.86Hz\n",
      "epoch: 1, train: 3/20, loss: 0.62039, frame: 12.29Hz/14.67Hz\n",
      "epoch: 1, train: 4/20, loss: 0.61372, frame: 14.25Hz/14.57Hz\n",
      "epoch: 1, train: 5/20, loss: 0.57272, frame: 14.15Hz/14.48Hz\n",
      "epoch: 1, train: 6/20, loss: 0.55888, frame: 13.88Hz/14.38Hz\n",
      "epoch: 1, train: 7/20, loss: 0.54104, frame: 14.86Hz/14.45Hz\n",
      "epoch: 1, train: 8/20, loss: 0.52805, frame: 14.66Hz/14.48Hz\n",
      "epoch: 1, train: 9/20, loss: 0.51376, frame: 13.45Hz/14.36Hz\n",
      "epoch: 1, train: 10/20, loss: 0.50144, frame: 15.13Hz/14.44Hz\n",
      "epoch: 1, train: 11/20, loss: 0.49109, frame: 12.06Hz/14.22Hz\n",
      "epoch: 1, train: 12/20, loss: 0.49254, frame: 11.63Hz/14.01Hz\n",
      "epoch: 1, train: 13/20, loss: 0.48154, frame: 14.33Hz/14.03Hz\n",
      "epoch: 1, train: 14/20, loss: 0.47506, frame: 13.45Hz/13.99Hz\n",
      "epoch: 1, train: 15/20, loss: 0.46798, frame: 11.21Hz/13.80Hz\n",
      "epoch: 1, train: 16/20, loss: 0.46991, frame: 10.99Hz/13.63Hz\n",
      "epoch: 1, train: 17/20, loss: 0.47284, frame: 13.22Hz/13.60Hz\n",
      "epoch: 1, train: 18/20, loss: 0.47264, frame: 13.57Hz/13.60Hz\n",
      "epoch: 1, train: 19/20, loss: 0.47621, frame: 12.70Hz/13.56Hz\n",
      "epoch: 1, train: 20/20, loss: 0.50269, frame: 13.47Hz/13.55Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-9a25d3e4bf17>:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idx_img = 1/idx_img\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, test: 1/186, pre: inf, gt:97.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 2/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.69Hz\n",
      "epoch: 1, test: 3/186, pre: inf, gt:23.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.56Hz/0.65Hz\n",
      "epoch: 1, test: 4/186, pre: inf, gt:44.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.66Hz\n",
      "epoch: 1, test: 5/186, pre: inf, gt:32.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.67Hz\n",
      "epoch: 1, test: 6/186, pre: inf, gt:49.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.83Hz/0.70Hz\n",
      "epoch: 1, test: 7/186, pre: inf, gt:41.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.70Hz\n",
      "epoch: 1, test: 8/186, pre: inf, gt:60.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.86Hz/0.72Hz\n",
      "epoch: 1, test: 9/186, pre: inf, gt:32.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.72Hz\n",
      "epoch: 1, test: 10/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.72Hz\n",
      "epoch: 1, test: 11/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.72Hz\n",
      "epoch: 1, test: 12/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.72Hz\n",
      "epoch: 1, test: 13/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 14/186, pre: inf, gt:24.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 15/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 16/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 17/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 18/186, pre: inf, gt:50.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.72Hz\n",
      "epoch: 1, test: 19/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.72Hz\n",
      "epoch: 1, test: 20/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.72Hz\n",
      "epoch: 1, test: 21/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.72Hz\n",
      "epoch: 1, test: 22/186, pre: inf, gt:31.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 23/186, pre: inf, gt:102.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.72Hz\n",
      "epoch: 1, test: 24/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.72Hz\n",
      "epoch: 1, test: 25/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.72Hz\n",
      "epoch: 1, test: 26/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 27/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.72Hz\n",
      "epoch: 1, test: 28/186, pre: inf, gt:20.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 29/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 30/186, pre: inf, gt:83.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.72Hz\n",
      "epoch: 1, test: 31/186, pre: inf, gt:14.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.72Hz\n",
      "epoch: 1, test: 32/186, pre: inf, gt:19.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 33/186, pre: inf, gt:17.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 34/186, pre: inf, gt:9.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 35/186, pre: inf, gt:31.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 36/186, pre: inf, gt:5.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.72Hz\n",
      "epoch: 1, test: 37/186, pre: inf, gt:39.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 38/186, pre: inf, gt:94.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 39/186, pre: inf, gt:37.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.59Hz/0.71Hz\n",
      "epoch: 1, test: 40/186, pre: inf, gt:68.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 41/186, pre: inf, gt:26.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 42/186, pre: inf, gt:37.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 43/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 44/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 45/186, pre: inf, gt:24.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 46/186, pre: inf, gt:83.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 47/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 48/186, pre: inf, gt:4.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.89Hz/0.71Hz\n",
      "epoch: 1, test: 49/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.72Hz\n",
      "epoch: 1, test: 50/186, pre: inf, gt:37.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.72Hz\n",
      "epoch: 1, test: 51/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 52/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.72Hz\n",
      "epoch: 1, test: 53/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.59Hz/0.71Hz\n",
      "epoch: 1, test: 54/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.63Hz/0.71Hz\n",
      "epoch: 1, test: 55/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 56/186, pre: inf, gt:56.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 57/186, pre: inf, gt:53.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 58/186, pre: inf, gt:65.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.64Hz/0.71Hz\n",
      "epoch: 1, test: 59/186, pre: inf, gt:21.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.42Hz/0.71Hz\n",
      "epoch: 1, test: 60/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.64Hz/0.70Hz\n",
      "epoch: 1, test: 61/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.70Hz\n",
      "epoch: 1, test: 62/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.71Hz\n",
      "epoch: 1, test: 63/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 64/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 65/186, pre: inf, gt:69.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.70Hz\n",
      "epoch: 1, test: 66/186, pre: inf, gt:65.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.70Hz\n",
      "epoch: 1, test: 67/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.70Hz\n",
      "epoch: 1, test: 68/186, pre: inf, gt:28.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.87Hz/0.71Hz\n",
      "epoch: 1, test: 69/186, pre: inf, gt:26.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 70/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 71/186, pre: inf, gt:104.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, test: 72/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 73/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 74/186, pre: inf, gt:36.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 75/186, pre: inf, gt:35.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 76/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.88Hz/0.71Hz\n",
      "epoch: 1, test: 77/186, pre: inf, gt:14.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 78/186, pre: inf, gt:13.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 79/186, pre: inf, gt:96.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 80/186, pre: inf, gt:9.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 81/186, pre: inf, gt:34.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 82/186, pre: inf, gt:68.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 83/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 84/186, pre: inf, gt:32.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 85/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 86/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.71Hz\n",
      "epoch: 1, test: 87/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 88/186, pre: inf, gt:117.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.71Hz\n",
      "epoch: 1, test: 89/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 90/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 91/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 92/186, pre: inf, gt:2.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 93/186, pre: inf, gt:2.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 94/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 95/186, pre: inf, gt:26.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 96/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 97/186, pre: inf, gt:59.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.88Hz/0.71Hz\n",
      "epoch: 1, test: 98/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.79Hz/0.71Hz\n",
      "epoch: 1, test: 99/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 100/186, pre: inf, gt:71.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 101/186, pre: inf, gt:67.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 102/186, pre: inf, gt:17.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.72Hz\n",
      "epoch: 1, test: 103/186, pre: inf, gt:13.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 104/186, pre: inf, gt:44.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 105/186, pre: inf, gt:54.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 106/186, pre: inf, gt:19.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 107/186, pre: inf, gt:17.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 108/186, pre: inf, gt:68.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 109/186, pre: inf, gt:19.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 110/186, pre: inf, gt:9.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 111/186, pre: inf, gt:42.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.63Hz/0.71Hz\n",
      "epoch: 1, test: 112/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 113/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 114/186, pre: inf, gt:2.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.82Hz/0.71Hz\n",
      "epoch: 1, test: 115/186, pre: inf, gt:56.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 116/186, pre: inf, gt:15.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 117/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 118/186, pre: inf, gt:47.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 119/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.65Hz/0.71Hz\n",
      "epoch: 1, test: 120/186, pre: inf, gt:41.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 121/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 122/186, pre: inf, gt:61.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 123/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 124/186, pre: inf, gt:47.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 125/186, pre: inf, gt:47.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 126/186, pre: inf, gt:21.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 127/186, pre: inf, gt:15.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 128/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 129/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 130/186, pre: inf, gt:3.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 131/186, pre: inf, gt:4.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.62Hz/0.71Hz\n",
      "epoch: 1, test: 132/186, pre: inf, gt:70.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.64Hz/0.71Hz\n",
      "epoch: 1, test: 133/186, pre: inf, gt:38.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.58Hz/0.71Hz\n",
      "epoch: 1, test: 134/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 135/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.63Hz/0.71Hz\n",
      "epoch: 1, test: 136/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.63Hz/0.71Hz\n",
      "epoch: 1, test: 137/186, pre: inf, gt:85.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 138/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 139/186, pre: inf, gt:44.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.65Hz/0.71Hz\n",
      "epoch: 1, test: 140/186, pre: inf, gt:62.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 141/186, pre: inf, gt:51.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.71Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, test: 142/186, pre: inf, gt:96.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.71Hz\n",
      "epoch: 1, test: 143/186, pre: inf, gt:18.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.66Hz/0.71Hz\n",
      "epoch: 1, test: 144/186, pre: inf, gt:100.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 145/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 146/186, pre: inf, gt:48.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 147/186, pre: inf, gt:5.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 148/186, pre: inf, gt:65.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 149/186, pre: inf, gt:53.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.71Hz\n",
      "epoch: 1, test: 150/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 151/186, pre: inf, gt:57.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 152/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.86Hz/0.71Hz\n",
      "epoch: 1, test: 153/186, pre: inf, gt:69.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 154/186, pre: inf, gt:52.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 155/186, pre: inf, gt:28.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 156/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 157/186, pre: inf, gt:5.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.64Hz/0.71Hz\n",
      "epoch: 1, test: 158/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.64Hz/0.71Hz\n",
      "epoch: 1, test: 159/186, pre: inf, gt:120.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.77Hz/0.71Hz\n",
      "epoch: 1, test: 160/186, pre: inf, gt:70.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 161/186, pre: inf, gt:61.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.76Hz/0.71Hz\n",
      "epoch: 1, test: 162/186, pre: inf, gt:24.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.88Hz/0.71Hz\n",
      "epoch: 1, test: 163/186, pre: inf, gt:66.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 164/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.66Hz/0.71Hz\n",
      "epoch: 1, test: 165/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.66Hz/0.71Hz\n",
      "epoch: 1, test: 166/186, pre: inf, gt:38.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 167/186, pre: inf, gt:16.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 168/186, pre: inf, gt:1.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 169/186, pre: inf, gt:16.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 170/186, pre: inf, gt:22.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, test: 171/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 172/186, pre: inf, gt:40.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 173/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 174/186, pre: inf, gt:14.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.68Hz/0.71Hz\n",
      "epoch: 1, test: 175/186, pre: inf, gt:54.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.71Hz/0.71Hz\n",
      "epoch: 1, test: 176/186, pre: inf, gt:64.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.87Hz/0.71Hz\n",
      "epoch: 1, test: 177/186, pre: inf, gt:41.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 178/186, pre: inf, gt:46.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.65Hz/0.71Hz\n",
      "epoch: 1, test: 179/186, pre: inf, gt:45.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 180/186, pre: inf, gt:63.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.74Hz/0.71Hz\n",
      "epoch: 1, test: 181/186, pre: inf, gt:4.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.75Hz/0.71Hz\n",
      "epoch: 1, test: 182/186, pre: inf, gt:12.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.70Hz/0.71Hz\n",
      "epoch: 1, test: 183/186, pre: inf, gt:50.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.67Hz/0.71Hz\n",
      "epoch: 1, test: 184/186, pre: inf, gt:33.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.73Hz/0.71Hz\n",
      "epoch: 1, test: 185/186, pre: inf, gt:90.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.72Hz/0.71Hz\n",
      "epoch: 1, test: 186/186, pre: inf, gt:0.00, me:inf, mae: inf, mse: inf, rmae: inf%, rmse: inf%, frame: 0.69Hz/0.71Hz\n",
      "epoch: 1, mae: inf, mse: inf, rmae: inf%, rmse: inf%, r2: nan\n",
      "tasselnetv2_rf110_i64o8_r0125_crop256_lr-2_bs9_epoch500 epoch 1 finished!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_mse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-ef1da3a8923c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEXP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' epoch {} finished!'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         print('best mae: {0:.2f}, best mse: {1:.2f}, best_rmae: {2:.2f}, best_rmse: {3:.2f}, best_r2: {4:.4f}'\n\u001b[1;32m---> 34\u001b[1;33m               .format(best_mae, best_mse, best_rmae, best_rmse, best_r2))\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mplot_learning_curves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSNAPSHOT_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_mse' is not defined"
     ]
    }
   ],
   "source": [
    "print('alchemy start...')\n",
    "#if evaluate_only:\n",
    "#validate(net, valset, val_loader, criterion, start_epoch, args)\n",
    "    #return\n",
    "\n",
    "best_mae = 1000000.0\n",
    "resume_epoch = -1 if start_epoch == 0 else start_epoch\n",
    "scheduler = MultiStepLR(optimizer, milestones=MILESTONES, gamma=0.1, last_epoch=resume_epoch)\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    # train\n",
    "    train(net, train_loader, criterion, optimizer, epoch + 1, args)\n",
    "    if epoch % VAL_EVERY == VAL_EVERY - 1:\n",
    "        # val\n",
    "        validate(net, valset, val_loader, criterion, epoch + 1, args)\n",
    "        # save_checkpoint\n",
    "        state = {\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': net.train_loss,\n",
    "            'val_loss': net.val_loss,\n",
    "            'measure': net.measure\n",
    "        }\n",
    "        save_checkpoint(state, SNAPSHOT_DIR, filename='model_ckpt.pth.tar')\n",
    "        if net.measure['mae'][-1] <= best_mae:\n",
    "            save_checkpoint(state, SNAPSHOT_DIR, filename='model_best.pth.tar')\n",
    "            best_mae = net.measure['mae'][-1]\n",
    "            best_mse = net.measure['mse'][-1]\n",
    "            best_rmae = net.measure['rmae'][-1]\n",
    "            best_rmse = net.measure['rmse'][-1]\n",
    "            best_r2 = net.measure['r2'][-1]\n",
    "        print(EXP + ' epoch {} finished!'.format(epoch + 1))\n",
    "        print('best mae: {0:.2f}, best mse: {1:.2f}, best_rmae: {2:.2f}, best_rmse: {3:.2f}, best_r2: {4:.4f}'\n",
    "              .format(best_mae, best_mse, best_rmae, best_rmse, best_r2))\n",
    "        plot_learning_curves(net, SNAPSHOT_DIR)\n",
    "    scheduler.step()\n",
    "\n",
    "print('Experiments with ' + EXP + ' done!')\n",
    "with open(os.path.join(SNAPSHOT_DIR, EXP + '.txt'), 'a') as f:\n",
    "    print(\n",
    "        'best mae: {0:.2f}, best mse: {1:.2f}, best_rmae: {2:.2f}, best_rmse: {3:.2f}, best_r2: {4:.4f}'\n",
    "            .format(best_mae, best_mse, best_rmae, best_rmse, best_r2),\n",
    "        file=f\n",
    "    )\n",
    "    print(\n",
    "        'overall best mae: {0:.2f}, overall best mse: {1:.2f}, overall best_rmae: {2:.2f}, overall best_rmse: {3:.2f}, overall best_r2: {4:.4f}'\n",
    "            .format(min(net.measure['mae']), min(net.measure['mse']), min(net.measure['rmae']),\n",
    "                    min(net.measure['rmse']), max(net.measure['r2'])),\n",
    "        file=f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate network\n",
    "net = CountingModels(\n",
    "      arc=args.model,\n",
    "      input_size=args.input_size,\n",
    "      output_stride=args.output_stride\n",
    "    )\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "#net.cuda()\n",
    "\n",
    "# filter parameters\n",
    "learning_params = [p[1] for p in net.named_parameters()]\n",
    "pretrained_params = []\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = nn.L1Loss(reduction='mean').cuda()\n",
    "\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(\n",
    "        [\n",
    "            {'params': learning_params},\n",
    "            {'params': pretrained_params, 'lr': args.learning_rate / args.mult},\n",
    "        ],\n",
    "        lr=args.learning_rate,\n",
    "        momentum=args.momentum,\n",
    "        weight_decay=args.weight_decay\n",
    "    )\n",
    "elif args.optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {'params': learning_params},\n",
    "            {'params': pretrained_params, 'lr': args.learning_rate / args.mult},\n",
    "        ],\n",
    "        lr=args.learning_rate\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# restore parameters\n",
    "start_epoch = 0\n",
    "net.train_loss = {\n",
    "    'running_loss': [],\n",
    "    'epoch_loss': []\n",
    "}\n",
    "net.val_loss = {\n",
    "    'running_loss': [],\n",
    "    'epoch_loss': []\n",
    "}\n",
    "net.measure = {\n",
    "    'mae': [],\n",
    "    'mse': [],\n",
    "    'rmae': [],\n",
    "    'rmse': [],\n",
    "    'r2': []\n",
    "}\n",
    "if args.restore_from is not None:\n",
    "    if os.path.isfile(args.restore_from):\n",
    "        checkpoint = torch.load(args.restore_from)\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "        if 'epoch' in checkpoint:\n",
    "            start_epoch = checkpoint['epoch']\n",
    "        if 'optimizer' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        if 'train_loss' in checkpoint:\n",
    "            net.train_loss = checkpoint['train_loss']\n",
    "        if 'val_loss' in checkpoint:\n",
    "            net.val_loss = checkpoint['val_loss']\n",
    "        if 'measure' in checkpoint:\n",
    "            net.measure['mae'] = checkpoint['measure']['mae'] if 'mae' in checkpoint['measure'] else []\n",
    "            net.measure['mse'] = checkpoint['measure']['mse'] if 'mse' in checkpoint['measure'] else []\n",
    "            net.measure['rmae'] = checkpoint['measure']['rmae'] if 'rmae' in checkpoint['measure'] else []\n",
    "            net.measure['rmse'] = checkpoint['measure']['rmse'] if 'rmse' in checkpoint['measure'] else []\n",
    "            net.measure['r2'] = checkpoint['measure']['r2'] if 'r2' in checkpoint['measure'] else []\n",
    "        print(\"==> load checkpoint '{}' (epoch {})\"\n",
    "              .format(args.restore_from, start_epoch))\n",
    "    else:\n",
    "        with open(os.path.join(args.snapshot_dir, args.exp + '.txt'), 'a') as f:\n",
    "            for item in arguments:\n",
    "                print(item, ':\\t', arguments[item], file=f)\n",
    "        print(\"==> no checkpoint found at '{}'\".format(args.restore_from))\n",
    "\n",
    "# define transform\n",
    "transform_train = [\n",
    "    RandomCrop(args.crop_size),\n",
    "    RandomFlip(),\n",
    "    Normalize(\n",
    "        args.image_scale,\n",
    "        args.image_mean,\n",
    "        args.image_std\n",
    "    ),\n",
    "    ToTensor(),\n",
    "    ZeroPadding(args.output_stride)\n",
    "]\n",
    "transform_val = [\n",
    "    Normalize(\n",
    "        args.image_scale,\n",
    "        args.image_mean,\n",
    "        args.image_std\n",
    "    ),\n",
    "    ToTensor(),\n",
    "    ZeroPadding(args.output_stride)\n",
    "]\n",
    "composed_transform_train = transforms.Compose(transform_train)\n",
    "composed_transform_val = transforms.Compose(transform_val)\n",
    "\n",
    "# define dataset loader\n",
    "trainset = dataset(\n",
    "    data_dir=args.data_dir,\n",
    "    data_list=args.data_list,\n",
    "    ratio=args.resize_ratio,\n",
    "    train=True,\n",
    "    transform=composed_transform_train\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "valset = dataset(\n",
    "    data_dir=args.data_dir,\n",
    "    data_list=args.data_val_list,\n",
    "    ratio=args.resize_ratio,\n",
    "    train=False,\n",
    "    transform=composed_transform_val\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print('alchemy start...')\n",
    "if args.evaluate_only:\n",
    "    validate(net, valset, val_loader, criterion, start_epoch, args)\n",
    "    return\n",
    "\n",
    "best_mae = 1000000.0\n",
    "resume_epoch = -1 if start_epoch == 0 else start_epoch\n",
    "scheduler = MultiStepLR(optimizer, milestones=args.milestones, gamma=0.1, last_epoch=resume_epoch)\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    # train\n",
    "    train(net, train_loader, criterion, optimizer, epoch + 1, args)\n",
    "    if epoch % args.val_every == args.val_every - 1:\n",
    "        # val\n",
    "        validate(net, valset, val_loader, criterion, epoch + 1, args)\n",
    "        # save_checkpoint\n",
    "        state = {\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': net.train_loss,\n",
    "            'val_loss': net.val_loss,\n",
    "            'measure': net.measure\n",
    "        }\n",
    "        save_checkpoint(state, args.snapshot_dir, filename='model_ckpt.pth.tar')\n",
    "        if net.measure['mae'][-1] <= best_mae:\n",
    "            save_checkpoint(state, args.snapshot_dir, filename='model_best.pth.tar')\n",
    "            best_mae = net.measure['mae'][-1]\n",
    "            best_mse = net.measure['mse'][-1]\n",
    "            best_rmae = net.measure['rmae'][-1]\n",
    "            best_rmse = net.measure['rmse'][-1]\n",
    "            best_r2 = net.measure['r2'][-1]\n",
    "        print(args.exp + ' epoch {} finished!'.format(epoch + 1))\n",
    "        print('best mae: {0:.2f}, best mse: {1:.2f}, best_rmae: {2:.2f}, best_rmse: {3:.2f}, best_r2: {4:.4f}'\n",
    "              .format(best_mae, best_mse, best_rmae, best_rmse, best_r2))\n",
    "        plot_learning_curves(net, args.snapshot_dir)\n",
    "    scheduler.step()\n",
    "\n",
    "print('Experiments with ' + args.exp + ' done!')\n",
    "with open(os.path.join(args.snapshot_dir, args.exp + '.txt'), 'a') as f:\n",
    "    print(\n",
    "        'best mae: {0:.2f}, best mse: {1:.2f}, best_rmae: {2:.2f}, best_rmse: {3:.2f}, best_r2: {4:.4f}'\n",
    "            .format(best_mae, best_mse, best_rmae, best_rmse, best_r2),\n",
    "        file=f\n",
    "    )\n",
    "    print(\n",
    "        'overall best mae: {0:.2f}, overall best mse: {1:.2f}, overall best_rmae: {2:.2f}, overall best_rmse: {3:.2f}, overall best_r2: {4:.4f}'\n",
    "            .format(min(net.measure['mae']), min(net.measure['mse']), min(net.measure['rmae']),\n",
    "                    min(net.measure['rmse']), max(net.measure['r2'])),\n",
    "        file=f\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
